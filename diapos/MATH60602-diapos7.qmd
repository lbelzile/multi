---
title: "Données manquantes et régression multinomiale"
subtitle: "Analyse multidimensionnelle appliquée"
date: ""
author: "Léo Belzile"
institute: "HEC Montréal"
format: beamer
navigation: empty
colortheme: Flip
innertheme: Flip
outertheme: Flip
themeoptions: "bullet=circle, topline=true, shadow=false"
beamerarticle: false
pdf-engine: lualatex
cache: true
code-line-numbers: true
fig-align: 'center'
mainfont: "VisbyCF-Medium"
mathfont: 'Latin Modern Math'
sansfont: 'Latin Modern Sans'
keep-tex: true
include-in-header: 
      text: |
        \usepackage{tabu}
        \usepackage{mathtools}
        \usepackage{mathrsfs}
---

<!--
# Données manquantes et inférence


- Les données manquantes réduisent la quantité d'information disponible et augmentent l'incertitude.
- On ne peut **pas** les ignorer (étude des cas complets) sans biaiser les interprétations et réduire la quantité d'information disponible.
- On considère des méthodes d'imputation qui remplacent les valeurs manquantes.

-->

# Données manquantes

Plusieurs champs d'une base de donnée peuvent être manquants 

- non-réponse
- valeurs erronées (erreur d'encodage)
- perte de suivi et censure
- plusieurs versions de formulaires (question optionnelles)

# Pourquoi s'en préoccuper?

La plupart des procédures ne gèrent que les cas complets (toute observation avec des valeurs manquantes est éliminée).

Les données manquantes réduisent l'information disponible.

Sans traitement adéquat, les estimations seront **biaisées**.

# Références

- van Buuren, S. (2018). [*Flexible imputation of missing data*](https://stefvanbuuren.name/fimd/), CRC Press, 2e édition.
- Little, R. et D. Rubin (2019). *Statistical Analysis with Missing Data*, Wiley, 3e édition
- Schafer, J. L. (1997). *Analysis of Incomplete Multivariate Data*. Chapman & Hall / CRC.

Les valeurs manquantes dans un contexte de prédictions sont couvertes dans le cours MATH 60600.

# Classification des données manquantes (MCAR)

Cas 1: Données manquantes de façon complètement aléatoire (*missing completely at random*)

La probabilité que la valeur soit manquante ne dépend ni de la valeur, ni de celles des autres variables.

Exemple: questionnaire trop long, la personne ne répond pas à tout (sans lien avec les questions posées).

Hypothèse souvent irréaliste en pratique.

# Classification des données manquantes (MAR)

Cas 2: données manquantes de façon aléatoire (*missing at random*): la probabilité que la valeur soit manquante ne dépend pas de la valeur *une fois qu'on a contrôlé pour les autres variables*.

Exemple: les hommes sont plus susceptibles dans l'ensemble de divulguer leur âge que les femmes.

# Classification des données manquantes (MNAR)

Cas 3: données manquantes de façon non-aléatoire (*missing not at random*): la probabilité que la mesure soit manquante dépend de la valeur elle-même, pas déterminable avec d'autres variables

Exemple: une personne transgenre ne répond pas à la question genre (si seulement deux choix, homme/femme) et aucune autre question ne se rattache au genre ou à l'identité sexuelle. 

# Type de données manquantes

Comment déterminer le type de données manquantes?

Par exemple, si une personne ne divulgue pas son salaire, est ce qu les données sont manquantes de manière aléatoire ou non aléatoire?

L'hypothèse pas testable, la réponse dépend du contexte et des variables auxiliaires disponibles.

# Valeur logique

Les données manquantes ont souvent une valeur logique:

- un client qui n'a pas de carte de crédit a un solde de 0!

D'où l'importance des validations d'usage et du nettoyage préliminaire de la base de données.


# Types de schémas de données manquantes

Matrice $n \times p$  (observations en lignes, variables en colonnes).

```{r}
#| eval: true
#| echo: false
#| out-width: '100%'
#| fig-height: 5
#| fig-width : 10
#| cache: true
library(patchwork)
library(ggplot2)
set.seed(1234)
tile <- expand.grid(1:8, 1:3)
colnames(tile) <- c("x", "y")
g1 <- ggplot(data = data.frame(tile, 
                               count = c(rep(0, 16), 
                                         rep(1, 3), 
                                         rep(0,5))),
             mapping = aes(y = factor(x), 
                           x = factor(y), 
                           fill = factor(count))) +
  geom_tile(colour = "white", linewidth = 2) +
  labs(x = "",
       y = "",
       fill = "",
       subtitle = "unidimensionnel") +
  scale_fill_discrete(palette = mice::mdc) + 
  scale_x_discrete(breaks = NULL, expand = c(0,0), labels = NULL) +
  scale_y_discrete(breaks = NULL, expand = c(0,0), labels = NULL) +
  theme_classic() +
  theme(legend.position = "none",
        axis.line = element_blank())

g2 <- ggplot(data = data.frame(tile, 
                               count = c(rep(0, 8), 
                                         rep(1, 2), 
                                         rep(0, 6), 
                                         rep(1, 4),
                                         rep(0, 4))),
             mapping = aes(y = factor(x), 
                           x = factor(y), 
                           fill = factor(count))) +
  geom_tile(colour = "white", linewidth = 2) +
  labs(x = "",
       y = "",
       fill = "",
       subtitle = "monotone") +
  scale_fill_discrete(palette = mice::mdc) + 
  scale_x_discrete(breaks = NULL, expand = c(0,0), labels = NULL) +
  scale_y_discrete(breaks = NULL, expand = c(0,0), labels = NULL) +
  theme_classic() +
    theme(legend.position = "none",
        axis.line = element_blank())
g3 <- ggplot(data = data.frame(tile, 
                               count = c(rep(0, 8), 
                                         rep(1, 5), 
                                         rep(0, 3), 
                                         rep(0, 5),
                                         rep(1, 3))),
             mapping = aes(y = factor(x), 
                           x = factor(y), 
                           fill = factor(count))) +
  geom_tile(colour = "white", linewidth = 2) +
  labs(x = "",
       y = "",
       fill = "",
       subtitle = "appariement") +
  scale_fill_discrete(palette = mice::mdc) + 
  scale_x_discrete(breaks = NULL, expand = c(0,0), labels = NULL) +
  scale_y_discrete(breaks = NULL, expand = c(0,0), labels = NULL) +
  theme_classic() +
    theme(legend.position = "none",
        axis.line = element_blank())
g4 <- ggplot(data = data.frame(tile, 
                               count = sample(c(0,1), 
                                              size = 24, 
                                              replace = TRUE, 
                                              prob = c(0.8, 0.2))),
             mapping = aes(y = factor(x), 
                           x = factor(y), 
                           fill = factor(count))) +
  geom_tile(colour = "white", linewidth = 2) +
  labs(x = "",
       y = "",
       fill = "",
       subtitle = "général") +
  scale_fill_discrete(palette = mice::mdc) + 
  scale_x_discrete(breaks = NULL, expand = c(0,0), labels = NULL) +
  scale_y_discrete(breaks = NULL, expand = c(0,0), labels = NULL) +
  theme_classic() +
    theme(legend.position = "none",
        axis.line = element_blank())

g1 + g2 + g3 + g4 + plot_layout(nrow = 1, byrow = FALSE)
```

\footnotesize

Les cases grises représentent des valeurs manquantes. Illustration adapté de la Figure 4.1 de van Buuren (2022)

# Analyse des cas complet

Retirer les observations avec données manquantes pour conserver les cas complets.

- Valide uniquement pour complètement aléatoire.
- On perd de la précision en utilisant moins d'observations.

Méthode par défaut dans les logiciels.


# Méthodes d'imputation


Imputation: remplacer les valeurs manquantes par une valeur judicieuse pour *combler les trous*.

> *Le concept d'imputation est à la fois séduisant et dangereux*. (Dempster et Rubin, 1983)

On distinguera 

- l'imputation déterministe (par exemple, remplacer les valeurs manquantes par la moyenne) versus aléatoire 
- l'imputation simple (une copie) versus multiple (plusieurs imputations)

# Imputation par la moyenne

Dilution de la relation (corrélation) entre variables explicatives. Réduction de la variabilité.

```{r}
#| echo: false
#| eval: true
#| out-width: '90%'
#| fig-width: 8
#| fig-align: 'center'
#| fig-height: 4
library(ggplot2)
set.seed(1234)
nobs <- 400L
ventes <- runif(n = nobs, min = 400, max = 800) + 
  rlnorm(n = nobs, meanlog = 4, sdlog = 1) -100 + 
  TruncatedNormal::rtnorm(n = 1, 
              mu = seq(100, to = 300, length.out = nobs), 
              sd = seq(0, 100, length.out = nobs),
              lb = 0, ub = 1000)
nbvisiteurs <- sort(rpois(n = nobs, lambda = 40))
full <- data.frame(ventes = ventes, 
                   nbclients = nbvisiteurs)
manquants <- as.matrix(full)
amputer <- mice::ampute(data = manquants, prop = 0.25)
# manquants[sample(x = c(TRUE, FALSE),
#                          size = 2*nobs, 
#                          replace = TRUE,
#                          prob = c(0.15,0.85))] <- NA
manquants1 <- amputer$amp |> 
  tibble::as_tibble() |>
  dplyr::mutate(
    manquant = dplyr::case_when(
      is.na(nbclients) | is.na(ventes) ~ 1,
      TRUE ~ 2),
    manqventes = dplyr::case_when(
      is.na(ventes) ~ 1,
      TRUE ~ 2), 
    manqnbclients = dplyr::case_when(
      is.na(nbclients) ~ 1,
      TRUE ~ 2),
    ventes = dplyr::case_when(
      is.na(ventes) ~ mean(ventes, na.rm = TRUE),
      TRUE ~ ventes),
    nbclients = dplyr::case_when(
      is.na(nbclients) ~ mean(nbclients, na.rm = TRUE),
      TRUE ~ nbclients))
g1 <- ggplot(data = manquants1,
       aes(x = nbclients, 
           y = ventes, 
           color = factor(1-manquant),
           shape = factor(manquant))) + 
  geom_point(size = 2) + 
    scale_shape_manual(values = c(1,20)) +
  scale_colour_discrete(palette = mice::mdc) +
  labs(y = "ventes",
       x = "nombre de clients") +
  theme_classic() +
  theme(legend.position = "none")

g2 <- ggplot(data = manquants1,
       aes(x = ventes,
           #y = after_stat(density),
           fill = factor(1-manqventes),
           group = factor(1-manqventes))) + 
  geom_histogram(alpha = 0.8) +
  scale_y_continuous(expand = c(0,0)) + 
  scale_fill_discrete(palette = mice::mdc) +
  labs(y = "") +
  theme_classic() +
  theme(legend.position = "none")
library(patchwork)
g2 + g1 
```

# Imputation aléatoire

Considérons le cas d'une régression logistique pour une variable explicative binaire.

Plutôt que d'assigner à la classe la plus probable, une prédiction aléatoire simule une variable 0/1 avec probabilité $(1-\widehat{p}_i, \widehat{p}_i)$.

```{r}
#| eval: true
#| echo: true
pred <- 0.3 #probabilité de succès
rbinom(n = 15, size = 1, prob = pred)
```


# Faut-il toujours imputer?

Il faut utiliser son jugement. 


Une observation imputée ne remplacera jamais une vraie observation.

- Si la proportion d'observations manquantes est petite (moins de 5\%), on pourrait faire une analyse avec les cas complets (et valider au besoin en utilisant l'imputation multiple).
- Si la proportion de  valeurs manquantes est 30\%  et que cette proportion baisse à 3\% lorsque vous éliminez quelques variables peu importantes pour votre étude, alors procédez à leur élimination.


# Problèmes de l'imputation simple

On ne tient pas compte du fait que des valeurs ont été remplacées (on fait comme si c'était de vraies observations). 

On sous-évalue encore une fois la **variabilité** des données

- les écarts-type des estimations sont trop petits.

# Inspection des valeurs manquantes

Il est donc nécessaire d'examiner la configuration des valeurs manquantes avant de faire quoi que ce soit. 

```{r}
#| label: manquantes-summary-uni
#| echo: true
#| eval: false
data(manquantes, package = 'hecmulti')
summary(manquantes)
# Pourcentage de valeurs manquantes
apply(manquantes, 2, function(x){mean(is.na(x))})
# Voir les configurations de valeurs manquantes
md.pattern(manquantes) # graphique diapo suivante
```

```{r}
#| label: tbl-manquantes-univ
#| cache: true
#| eval: true
#| echo: false
#| tbl-cap: "Nombre et pourcentage de valeurs manquantes par variable."
data(manquantes, package = 'hecmulti')
manq <- formatC(apply(manquantes, 2, 
                      function(x){c(sum(is.na(x)), 100*mean(is.na(x)))}))
rownames(manq) <- c("nombre", "pourcentage")
knitr::kable(manq,
             booktabs = TRUE) |>
  kableExtra::kable_styling()
```

# Configuration des valeurs manquantes

```{r}
#| label: fig-manquantes2
#| echo: false
#| eval: true
#| out-width: '50%'
#| fig-cap: "Les noms des variables sont indiquées au dessus, le nombre total de valeurs manquantes par variable en dessous, le nombre d’observations pour chaque configuration de valeurs manquantes à gauche et le nombre de variables avec des valeurs manquantes par configuration à droitef."
puzle <- mice::md.pattern(hecmulti::manquantes[,1:6], 
                          plot = TRUE)
```





# Imputation multiple

Valides pour les données manquantes de manière aléatoire et complètement aléatoires (MAR et MCAR).

1. Procéder à plusieurs imputations **aléatoires** pour obtenir un échantillon complet (`mice`)
2. Ajuster le modèle d'intérêt avec chaque échantillon (`with`). 
3. Combiner les résultats obtenus (`pool` et `summary`)

```{r}
#| eval: true
#| echo: false
#| out-width: '70%'
#| fig-align: 'center'
knitr::include_graphics("figures/donnees_manquantes_workflow.pdf")
```

# Combinaison des résultats

Considérons un seul paramètre $\theta$ (ex: coefficient d'une régression) et supposons qu'on procède à $K$ imputations.

On estime les paramètres du modèle séparément pour chacun des $K$ ensembles de données imputés, disons 

- $\widehat{\theta}_k$ pour l'estimation du paramètre $\theta$ dans l'échantillon $k$ et
- $\widehat{\sigma}_k^2=\mathsf{Va}(\widehat{\theta}_k)$ pour l'estimation de la variance de $\widehat{\theta}_k$. 

# Estimations

L'estimation finale de $\theta$, dénotée $\widehat{\theta}$, est obtenue tout simplement en faisant la moyenne des estimations de tous les modèles.

Pour la variance de $\widehat{\theta}$, on calcule la somme de

- la moyenne des $K$ variances pour chaque imputation, $\widehat{\sigma}_1^2, \ldots, \widehat{\sigma}_K^2$, appelée variance intra-groupe.
- la variance des estimations moyennes, $\widehat{\theta}_1, \ldots, \widehat{\theta}_K$, appelée variance inter-groupe.

En combinant ces deux sources variabilités, on enfle la variance par rapport à l'imputation simple

<!-- 

# Imputation multiple

Des formules analogues existent pour les degrés de liberté, les valeurs-$p$, etc. ainsi que pour la cas multidimensionnel (plusieurs paramètres).

Si on procédait à une seule imputation (même en ajoutant une part d'aléatoire pour essayer de reproduire la variabilité des données), on ne serait pas en mesure d'estimer la variance inter-groupe de l'estimateur. 

On peut estimer la fraction de l'information manquante sur $\theta$ avec $(1+1/K)B/\mathsf{Va}(\hat{\theta})$. 

-->


# Imputation multiple par équations chaînées (MICE)

Avec $p$ variables $X_1, \ldots, X_p$, spécifier un ensemble de modèles **conditionnels** pour chaque variable $X_j$ en fonction de

- toutes les autres variables, $\boldsymbol{X}_{-j}$
- les valeurs observées pour cette variable, $X_{j, \text{obs}}$

1. Initialisation: remplir les trous avec des données au hasard parmi $X_{j, \text{obs}}$ pour $X_{j, \text{man}}$
2. À l'itération $t$, pour chaque variable $j=1, \ldots, p$, à tour de rôle:
   a) tirage aléatoire des paramètres $\phi_j^{(t)}$ du modèle pour $X_{j,\text{man}}$ conditionnel à $\boldsymbol{X}_{-j}^{(t-1)}$ et  $X_{j, \text{obs}}$
   b) échantillonnage de nouvelles observations $X^{(t)}_{j,\text{man}}$ du modèle avec paramètres $\phi_j^{(t)}$ conditionnel à $\boldsymbol{X}_{-j}^{(t-1)}$ et  $X_{j, \text{obs}}$
3. Répéter le cycle



# Imputation multiple avec `mice`



```{r}
#| label: manquante2
#| eval: false
#| echo: true
library(mice)
# Intensif en calcul, réduire "m" si nécessaire
impdata <- mice(
   data = manquantes,
   # argument "method" pour le modèle
   # dépend du type des variables, par ex.
   # régression logistique pour données binaires
   m = 50, # nombre d'imputations
   seed = 60602, # germe aléatoire
   printFlag = FALSE)
# Extraite une copie (m=1,..., 50) imputée 
complete(data = impdata, 
         action = 1) #no de la copie
```

# Estimation et combinaison avec `mice`

```{r}
#| eval: false
#| echo: true
# ajuste le modèle avec les données imputées
adj_im <- with(
  data = impdata,
  expr = glm(y ~ x1 + x2 + x3 + x4 + x5 + x6,
             family = binomial))
# combinaison des résultats 
fit <- pool(adj_im)
summary(fit)
```


# Résultats {.smaller}

- Les estimations avec les données complètes ont la plus grande incertitude, parce qu'elles utilisent uniquement $n=180$ observations.
- L'imputation multiple donne $n=500$ observations et prend correctement en compte l'incertitude.
- L'imputation simple sous-estime l'incertitude des coefficients.

```{r}
#| label: tbl-manquantsres
#| eval: true
#| echo: false
#| cache: true
#| tbl-cap: "Estimation des coefficients et erreurs type pour quelques paramètres du modèle."
library(mice)
# Intensif en calcul, réduire "m" si nécessaire
data(manquantes, package = "hecmulti")
complet <- glm(y ~ ., family = binomial, data = manquantes)

impdata <- mice(data = hecmulti::manquantes,
                # argument method pour le type de modèles
                # selon les variables
                m = 50, # nombre d'imputations
                seed = 60602, # germe aléatoire
                printFlag = FALSE)
imp_simple <- glm(y ~ ., family = binomial, data = complete(impdata, 1))
# ajuste le modèle avec les données imputées
adj_im <- with(
  data = impdata,
  expr = glm(y ~ x1 + x2 + x3 + x4 + x5 + x6,
             family = binomial))
# combinaison des résultats 
fit <- pool(adj_im)


tab <- cbind(summary(complet)$coefficients[2:6,1:2],
             summary(fit)[2:6,2:3], 
             summary(imp_simple)$coefficients[2:6,1:2])
colnames(tab) <- paste0(rep(c("est","stderr"), length.out = 6), rep(1:3, each = 2))

library(gt)
tab |>
  gt() |>
  fmt_number(columns = everything(), decimals = 2) |>
  cols_label(
    starts_with("est") ~ "coef.",
    starts_with("stderr") ~ "err. type"
  ) |>
   tab_spanner(
    label = "imputation multiple",
    columns = 3:4) |>
   tab_spanner(
    label = "données complètes",
    columns = 1:2) |>
  tab_spanner(
    label = "imputation simple",
    columns = 5:6)|>
  as_latex()
# fit_df_mi <- tibble::as_tibble(summary(fit))
# fit_df_mi$p.value <- format.pval(fit_df$p.value,
#                               digits = 1, 
#                               eps = 1e-4)
# knitr::kable(gt_tbl, 
#              digits = 2, 	
#              booktabs = TRUE,
#              linesep = "") |>
#   kableExtra::kable_styling()
```

# Récapitulatif

- Les données manquantes réduisent la quantité d'information disponible et augmentent l'incertitude.
- On ne peut **pas** les ignorer (étude des cas complets) sans biaiser les interprétations et réduire la quantité d'information disponible.
- Pour bien capturer l'**incertitude** et ne pas modifier les relations entre variables, il faut utiliser une méthode **aléatoire**.
- Avec l'algorithme MICE, on utilise un modèle conditionnel pour chaque variable à tour de rôle

# Récapitulatif

L'imputation multiple est préférée à l'imputation simple car elle permet d'estimer l'incertitude sous-jacente en raison des données manquantes.

- On procède à l'imputation plusieurs fois (avec un modèle conditionel, prédictions différentes chaque fois)
- on crée plusieurs copies
- ajuste le modèle sur chacune et 
- combine les résultats

Traitement spécial pour erreurs-type, degrés de liberté, valeurs-$p$ et intervalles de confiance.



# Taux de participation lors des élections américaines

Les [données](https://github.com/fivethirtyeight/data/tree/master/non-voters) de cet exemple sont tirées d'un sondage Ipsos réalisé pour le site de nouvelles *FiveThirtyEight*. 

La base de données `vote` contient 5837 observations avec les pondérations associées.

Nous allons modéliser l'intention de vote, `catvote` à l'aide d'une régression logistique multinomiale. Il y a trois modalités possible (rarement ou jamais, occasionnellement et toujours).

# Analyse exploratoire

```{r}
#| label: fig-multinom_means-Ipsos
#| echo: false
#| eval: true
#| out-width: '80%'
#| fig-width: 8
#| fig-height: 6
#| cache: true
#| fig-cap: "Proportion des modalités des variables sociodémographiques des données de participation électorale."
library(ggplot2)
library(dplyr)
library(patchwork)
data(vote, package = "hecmulti")
g1 <- vote |> 
  dplyr::count(revenu, catvote, wt = poids) |>
ggplot(aes(fill = catvote,
           x = n,
           y = revenu)) +
  ggplot2::geom_bar(position = "fill",
                    stat = "identity") +
  scale_x_continuous(name = NULL,
                     position = "top",
                     expand = c(0,0),
                     breaks = c(0, 0.25,0.5,0.75,1),
                     labels = c("0%","25","50","75","100")) +
  scale_y_discrete(expand = c(0,0)) +
  labs(subtitle = "revenu", 
       x = "", y = "", fill = "vote") +
  theme_classic()
g2 <- vote |> 
  dplyr::count(sexe, catvote, wt = poids) |>
ggplot(aes(fill = catvote,
           x = n,
           y = sexe)) +
  ggplot2::geom_bar(position = "fill",
                    stat = "identity") +
  scale_x_continuous(name = NULL,
                     position = "top",
                     expand = c(0,0),
                     breaks = c(0, 0.25,0.5,0.75,1),
                     labels = c("0%","25","50","75","100")) +
  scale_y_discrete(expand = c(0,0)) +
  labs(subtitle = "sexe", 
       x = "", y = "", fill = "vote") +
  theme_classic()
g3 <- vote |> 
  dplyr::count(race, catvote, wt = poids) |>
ggplot(aes(fill = catvote,
           x = n,
           y = race)) +
  ggplot2::geom_bar(position = "fill",
                    stat = "identity") +
  scale_x_continuous(name = NULL,
                     position = "top",
                     expand = c(0,0),
                     breaks = c(0, 0.25,0.5,0.75,1),
                     labels = c("0%","25","50","75","100")) +
  scale_y_discrete(expand = c(0,0)) +
  labs(subtitle = "race", 
       x = "", y = "", fill = "vote")+
  theme_classic()
g4 <- vote |> 
  dplyr::count(educ, catvote, wt = poids) |>
ggplot(aes(fill = catvote,
           x = n,
           y = educ)) +
  ggplot2::geom_bar(position = "fill",
                    stat = "identity") +
  scale_x_continuous(name = NULL,
                     position = "top",
                     expand = c(0,0),
                     breaks = c(0, 0.25,0.5,0.75,1),
                     labels = c("0%","25","50","75","100")) +
  scale_y_discrete(expand = c(0,0)) +
  labs(subtitle = "niveau d'éducation", 
       x = "", y = "", fill = "vote")+
  theme_classic()
g5 <- vote |> 
  dplyr::count(affiliation, catvote, wt = poids) |>
ggplot(aes(fill = catvote,
           x = n,
           y = affiliation)) +
  ggplot2::geom_bar(position = "fill",
                    stat = "identity") +
  scale_x_continuous(name = NULL,
                     position = "top", 
                     expand = c(0,0),
                     breaks = c(0, 0.25,0.5,0.75,1),
                     labels = c("0%","25","50","75","100")) +
  scale_y_discrete(expand = c(0,0)) +
  labs(subtitle = "affiliation politique", 
       x = "", y = "", fill = "vote")+
  theme_classic()
g6 <- vote |> 
  mutate(agecat = with(vote, cut(age, c(20,40,60,100)))) |>
  dplyr::count(agecat, catvote, wt = poids) |>
ggplot(aes(fill = catvote,
           x = n,
           y = agecat)) +
  ggplot2::geom_bar(position = "fill",
                    stat = "identity") +
  scale_x_continuous(name = NULL,
                     position = "top", 
                     breaks = c(0, 0.25,0.5,0.75,1),
                     labels = c("0%","25","50","75","100"),
                     expand = c(0,0)) +
  scale_y_discrete(expand = c(0,0)) +
  labs(subtitle = "âge", 
       x = "", y = "", fill = "vote") +
  theme_classic()
(g1 + g2) / (g3 +g4) / (g5 + g6) + plot_layout(guides = "collect") & theme(legend.position = "bottom")
```


# Analyse exploratoire


```{r}
#| message: false
#| warning: false
#| eval: true
#| echo: false
#| label: figure-age
votecat <- as.integer(factor(vote$catvote, ordered = FALSE))-1L
mod <- mgcv::gam(
  formula = list(
    votecat ~ s(age, bs = "cr"), 
            ~ s(age, bs = "cr")), 
  weights = poids,
  family = mgcv::multinom(K = 2), 
  data = vote)

newage <- 20:90
nb <- length(newage)
pred <- c(predict(mod,
                newdata = data.frame(age = newage), 
                type = "response"))
cat <- factor(rep(c("rarement/jamais","occasionnellement","toujours"), each = nb))
cat <- relevel(cat, ref = "rarement/jamais")
ggplot(data = data.frame(age = rep(newage, 3L*nb),
                         pred = pred, 
                         cat = cat),
       mapping = aes(x = age, y = pred, col = cat, group = cat)) + 
  geom_line() + 
  scale_y_continuous(limits = c(0,1), 
                     expand = c(0,0),
                     labels = scales::percent) + 
  labs(color = "catégorie de vote",
       x = "âge)",
       y = "",
       subtitle = "Proportion par catégorie de vote (lissage)") +
  viridis::scale_color_viridis(discrete = TRUE) + 
  theme_classic() +
  theme(legend.position = "bottom")
```


# Analyse exploratoire  (`age`)

```{r}
#| label: fig-vote-age
#| eval: true
#| echo: false
#| fig-width: 6
#| fig-height: 4
#| out-width: '70%'
#| fig-cap: "Fréquence de vote selon l'âge."
ggplot(data = vote, 
       aes(x = age, fill = catvote)) +
  geom_density(alpha = 0.2) + 
  labs(fill = "vote", 
       x = "âge (années)", 
       y = "densité") + 
  theme(legend.position = "bottom") +
  theme_minimal()
```

Notez le comportement des jeunes voteurs (bimodal). Ces personnes n'ont souvent eu qu'une seule occasion de voter...


# Régression pour données multinomiale

On considère une variable réponse catégorielle avec $K \ge 2$ modalités.

**Objectif**: modéliser la probabilité de chaque catégorie de la variable réponse.

Soit la probabilité d'appartenir à la modalité $k$, $$p_{ik} = \Pr(Y_i=k \mid \mathrm{X}_i), \qquad (k=1, \ldots, K).$$ 

La somme des probabilités, $p_{i0} + \cdots + p_{iK}$, vaut 1.

# Modèle multinomial logistique 

Comme avec la régression logistique, on fixe une catégorie de référence (disons $1$) et on modélise le log de la cote de chacune des autres catégories par rapport à cette référence,
\begin{align*}
 \ln\left(\frac{p_{ij}}{p_{i1}}\right) = \eta_{ij} = \beta_{0j} + \cdots + \beta_{pj} \mathrm{X}_{ip}, \quad (j=2, \ldots, K).
\end{align*}

- Avec $K$ modalités et $p$ variables explicatives, on obtiendra $(K-1)\times (p+1)$ paramètres à estimer, en incluant l'ordonnée à l'origine.

L'interprétation des paramètres se fait comme en régression logistique sauf qu'il faut y aller équation par équation.

# Modèle logistique multinomial et probabilités

On peut aussi exprimer le modèle en termes des probabilités, 
\begin{align*}
 p_{ik} &= \Pr(Y_i=k \mid \mathbf{X}_i) \\&= \frac{\exp(\eta_{ik})}{1+ \exp(\eta_{i2}) + \cdots + \exp(\eta_{iK})}, \qquad k =1, \ldots, K.
\end{align*}
où $\eta_{ij}$ est le prédicteur linéaire de l'individu $i$ pour le log de la cote de $Y_i=j$ versus la référence $Y_i=1$. On fixe $\eta_{i1}=0$.


# Ajustement du modèle

La fonction `multinom` du paquet `nnet` ajuste le modèle multinomial logistique.

```{r}
#| label: mullogit
#| eval: true
#| echo: true
data(vote, package = "hecmulti")
levels(vote$catvote)
# Modèle multinomial
multi1 <- nnet::multinom(
  catvote ~ age + sexe + race + revenu + 
    educ + affiliation, 
  data = vote,       # base de données
  subset = age > 30, # sous-ensemble des données
  weights = poids,   # poids de sondage
  trace = FALSE)     # infos sur convergence
```

# Méthodes **R** pour l'analyse

```{r}
#| eval: false
#| echo: true
# Tableau résumé de l'ajustement
summary(multi1)
# Estimations des coefficients
coef(multi1)
# Intervalles de confiance (Wald)
confint(multi1)
# Critères d'information
AIC(multi1)
BIC(multi1)
# Prédiction: probabilité de chaque modalité
predict(multi1, type = "probs")
# Prédiction: classe la plus susceptible
predict(multi1, type = "class")
```

# Comparaison de modèles emboîtés

Le modèle avec uniquement l'ordonnée à l'origine possède $K-1$ paramètres.
Il retourne comme probabilité prédite la proportion empirique de chaque catégorie.

```{r}
#| eval: true
#| echo: true
multi_cst <- nnet::multinom(
  catvote ~ 1,
  weights = poids,
  subset = age > 30,
  data = vote,
  trace = FALSE)
head(predict(multi_cst, type = "probs"), n = 3)
```


# Tests de rapport de vraisemblance

On peut comparer des modèles emboîtés avec la fonction `anova`: ici, on compare le modèle complet au même modèle, moins la variable `sexe`.

```{r}
#| eval: false
multi0 <- nnet::multinom(
  catvote ~ age + race + revenu + educ + affiliation,
  weights = poids,
  subset = age > 30,
  data = vote,
  trace = FALSE)
# Test de rapport de vraisemblance
anova(multi0, multi1)
```

```{r}
#| eval: true
#| echo: false
multi0 <- nnet::multinom(
  catvote ~ age + race + revenu + educ + affiliation,
  weights = poids,
  subset = age > 30,
  data = vote,
  trace = FALSE)
# Test de rapport de vraisemblance
options(knitr.kable.NA = '')
knitr::kable(
  anova(multi0, multi1)[,-c(1,4)], 
  col.names = c("ddl resid", "deviance", "ddl","stat", "valeur-p"), 
  booktabs = TRUE,
  digits = 2)
```

La différence est significative à niveau 5%, l'effet de `sexe` est non null.

# Prédictions

Pour un profil $\mathbf{X}_i$ donné, on peut 

- calculer chacun des $K-1$ prédicteurs linéaires $\widehat{\eta}_{i2}, \ldots, \widehat{\eta}_{iK}$.
- écrire $p_{ik} = p_{i1}\exp(\widehat{\eta}_{ik})$ (formule de la cote)
- substituer cette mesure dans l'équation $p_{i1} + \cdots + p_{iK}=1$
- isoler la prédiction numérique pour $p_{i1}$.
- en déduire les probabilités de succès de chaque modalité de $Y$.

**Exemple au tableau**


# Classification

La prédiction du modèle est une probabilité pour chacune des $K$ modalités.


On peut toujours classifier les événements 

- avec $K-1$ points de coupure...
- ou assigner à la modalité la plus probable

Avec les prédictions, on peut comparer les observations et les prédictions à l'aide d'une matrice de confusion $K \times K$.

- Le taux de bonne classification est toujours valide
- Il existe des extensions multidimensionnelles de l'aire sous la courbe

# Matrice de confusion

```{r}
#| tbl-cap: "Prédictions (lignes) versus observations (colonnes) pour le résultat du sondage pour les personnes âgées de plus de 30 ans."
#| label: tbl-confusmat
#| eval: true
#| echo: false
catvote <- with(vote, catvote[age > 30])
levels(catvote) <- c("rare", "occas.", "toujours")
pred <- predict(multi1, type = "class")
levels(pred) <- c("rare", "occas.", "toujours")
tab <- table(pred, catvote)
knitr::kable(tab, digits = 0, booktabs = TRUE)
```

Le taux de bonne classification est `r sum(diag(tab))`/`r sum(tab)`=`r round(sum(diag(tab))/sum(tab), 2)`.

# Commentaires

- Contrairement à la régression logistique, le nombre de paramètres augmente rapidement avec le nombre de variables explicatives, $p$.
- Il y a moins d'information pour estimer les paramètres qu'une régression linéaire: prévoir de plus grandes tailles d'échantillon.
- Attention aux modalités à faible fréquence et à la répartition des variables explicatives au sein des différentes modalités.

# Données ordinales

Outre la régression multinomiale logistique, on peut également considérer la *régression logistique cumulative à cotes proportionnelles*.


- modèle plus parcimonieux que le modèle multinomial logistique,
- mais au prix de postulats supplémentaires...

Voir les notes de cours pour plus de détails.

<!--
En **R**, la variable réponse doit être de classe `ordered`, un facteur dont les niveaux sont ordonnés en ordre croissant. Voir
```{r}
#| echo: true
#| eval: true
class(hecmulti::vote$catvote)
```

# Notation du modèle

- Soit $p_1, \ldots, p_K$ les probabilités associées aux événements $Y=1, \ldots$
- On définit les points de coupure pour les $K$ classes,
$$ -\infty = \zeta_0 < \zeta_1 < \cdots < \zeta_K = \infty.$$
- Il y a $K-1$ paramètres $\zeta$ à déduire pour identifier les probabilités puisque $p_1 + \cdots + p_K=1$.

#  Formulation du modèle

Le modèle logistique à cote proportionnelle spécifie $K-1$ équations logistiques; pour $k=1, \ldots, K-1$,
\begin{align*}
\ln \left(\frac{\Pr(Y_i> k\mid \mathbf{X}_i)}{\Pr(Y_i \le k\mid \mathbf{X}_i)}\right) = -\zeta_k + \beta_1 \mathrm{X}_{i1} + \cdots + \beta_p \mathrm{X}_{ip}.
\end{align*}

- Les paramètres associés aux variables explicatives, $\beta_1, \ldots, \beta_p$ sont les **mêmes** pour chacune des log-cotes
- mais il y a une ordonnée à l'origine différente par rapport de cote, $-\zeta_k$. 


# Interprétation des paramètres

On considère la cote de $\Pr(Y_i> k\mid \mathbf{X}_i)$ versus $\Pr(Y_i \le k\mid \mathbf{X}_i)$, qui mesure à quel point il est plus probable que $Y_i$ prenne une valeur supérieure à $k$ par rapport à une valeur inférieure ou égale à $k$, avec

Pour chaque augmentation d'une unité de $\mathrm{X}_j$, cette cote est multipliée par $\exp(\beta_j)$, peu importe la valeur de $Y$ (**cote proportionnelle**). 

# Interprétation des coefficients

```{r}
#| label: tbl-ordered-logistic
#| tbl-cap: "Tableau des estimations des coefficients du modèle pour réponses ordinales à cotes proportionnelles."
#| echo: false
#| eval: true
#| message: false
#| warning: false
multi2a <- MASS::polr(catvote ~ sexe, 
                      data = vote,
                      subset = age > 30,
                      weights = poids,
                      method = "logistic", 
                      Hess = TRUE)
# multi2b <- nnet::multinom(
#   catvote ~ affiliation, 
#   data = vote,
#   subset = age > 30,
#   weights = poids,
#   Hess = TRUE,
#   trace = FALSE)
rapp <- summary(multi2a)
coefs <- rapp$coefficients
options(knitr.kable.NA = '')
tabcoef <- tibble::as_tibble(coefs[,1:2])
tabcoef <- cbind("effet" = c("sexe [homme]","cst [rarement/jamais|occas.]","cst [occas.|toujours]"), tabcoef)
kableExtra::kbl(tabcoef,
	        longtable = FALSE, 
	        booktabs = TRUE,
          col.names = c("effet","coefficient","erreur-type"),
          digits = 3,
	        format = "latex")
pval_lrt_multi2a_drop1 <- sprintf(round(drop1(multi2a, test = "Chisq")[2,4],3), fmt = "%.3f")
```

Les hommes de plus de 30 ans sont moins susceptibles de voter fréquemment que les femmes. 

La cote catégorie plus fréquente de vote (vs moins fréquente) pour les hommes est $\exp(`r sprintf(round(as.numeric(coef(multi2a)),3), fmt = "%.3f")`)=`r sprintf(round(exp(as.numeric(coef(multi2a))),3), fmt = "%.3f")`$ fois celle des femmes, soit une diminution de $`r round(100*(1-exp(as.numeric(coef(multi2a)))), 1)`\%$ de la cote.

# Ajustement dans **R**

Pour simplifier, on utilise uniquement `sexe` comme variable explicative.

```{r}
#| label: ordinal-logistique
#| eval: false
#| echo: true
#| warning: false
#| error: false
# with(vote, is.ordered(catvote))
multi2a <- MASS::polr(
  catvote ~ sexe, 
  data = vote, 
  subset = age > 30,
  weights = poids,
  method = "logistic", 
  Hess = TRUE)
summary(multi2a)
```

```{r}
#| label: ordinal-logistique-eval
#| eval: true
#| echo: false
#| warning: false
#| error: false
# with(vote, is.ordered(catvote))
multi2a <- MASS::polr(
  catvote ~ sexe, 
  data = vote, 
  subset = age > 30,
  weights = poids,
  method = "logistic", 
  Hess = TRUE)
expit <- function(x){ exp(x)/(1+exp(x))}
```


# Méthodes pour `polr`


```{r}
#| echo: true
#| eval: false
# IC pour beta_x (vraisemblance profilée)
confint(multi2a)
# On peut obtenir les intervalles de Wald 
# avec confint.default (PAS RECOMMANDÉ)

# Critères d'information
AIC(multi2a); BIC(multi2a)
# Tableau des coefficients 
# Coefficients (variables explicatives)
coef(multi2a)
# Négatif de l'ordonnée à l'origine:
multi2a$zeta
```

# Coefficients pour l'ordonnée à l'origine


Si on écrit les équations pour la cote, on obtient
\begin{align*}
\frac{\Pr(Y = \texttt{rarement} \mid \texttt{sexe})}{\Pr(Y \geq \texttt{occas.} \mid \texttt{sexe})} &= \exp(`r round(coef(multi2a)[1], 3)`\texttt{sexe} `r paste(ifelse(multi2a$zeta[1] < 0, "+","-"), round(abs(multi2a$zeta[1]), 3))`) \\ 
\frac{\Pr(Y \leq \texttt{occas.} \mid \texttt{sexe})}{\Pr(Y = \texttt{toujours} \mid \texttt{sexe})} &= \exp(`r round(coef(multi2a)[1], 3)`\texttt{sexe} `r paste(ifelse(multi2a$zeta[2] < 0, "+","-"), round(abs(multi2a$zeta[2]), 3))`).
\end{align*}

# Probabilités prédites

En terme de probabilité cumulée d'excéder $k\in \{1, \ldots, K-1\}$,
\begin{align*}
\Pr(Y_i > k \mid \mathbf{X}_i) &= \textrm{expit}(-\eta_k + \beta_1 \mathrm{X}_{i1} + \cdots + \beta_p \mathrm{X}_{ip}).
\end{align*}
En utilisant ces expressions, on peut obtenir la probabilité de chaque catégorie,
\begin{align*}
&\Pr(Y_i = k \mid \mathbf{X}_{i}) =\Pr(Y_i > k \mid \mathbf{X}_{i}) - \Pr(Y_i > k-1 \mid \mathbf{X}_{i}).
\end{align*}

# Prédictions

- Soit $p_1 = \Pr(Y = \texttt{rarement/jamais} \mid \texttt{femme})$, etc. 
- On a $\mathrm{expit}(\zeta_k)$ ($k=0, \ldots, K$) qui donne $0$, $`r round(expit(multi2a$zeta)[1], 3)`$, $`r round(expit(multi2a$zeta)[2], 3)`$ et $1$.
- Les différences donnent $\widehat{p}_1 = `r round(expit(multi2a$zeta)[1], 3)`$, $\widehat{p}_2 = `r round(expit(multi2a$zeta)[2]-expit(multi2a$zeta)[1], 3)`$ et $\widehat{p}_3 = `r round(1-expit(multi2a$zeta)[2], 3)`$. 
- Un rapide calcul numérique montre que c'est bien ce que retourne les prédictions.

```{r}
#| eval: false
#| echo: true
predict(multi2a, 
        newdata = data.frame(sexe = factor("femme")), 
        type = "probs")
```


# Postulat de rapport de cote proportionnel

Une des hypothèses de ce modèle est que les effets des variables explicatives sont les mêmes pour chaque équation. 

- $\mathscr{H}_0$ : l'effet de chaque variable est le même pour les $K$ logit du modèle .

Une très petite valeur-$p$ (rejet de $\mathscr{H}_0$) pour ce test serait une indication que le modèle multinomial logistique serait préférable. 

# Test de rapport de vraisemblance 

Ce test compare les deux modèles emboîtés, avec 

- hypothèse nulle $\mathscr{H}_0$: modèle cumulatif à cotes proportionnelles, avec $p+K-1$ paramètres
- hypothèse alternative $\mathscr{H}_a$: modèle multinomial, avec $(K-1)\times(p+1)$ paramètres


```{r}
#| eval: true
#| echo: true
multi2b <- nnet::multinom(catvote ~ sexe, 
  data = vote,  subset = age > 30, 
  weights = poids, trace = FALSE)
# Valeur-p du test de rapport de vraisemblance
pchisq(q = deviance(multi2a) - deviance(multi2b),
       df = length(coef(multi2a)), 
       lower.tail = FALSE)
```

Le modèle sous $\mathscr{H}_0$ semble être une simplification adéquate.

# Test du rapport de vraisemblance


```{r}
#| eval: true
#| echo: false
multi3a <- MASS::polr(
  catvote ~ age, 
  data = vote, 
  subset = age > 30,
  weights = poids,
  method = "logistic", 
  Hess = TRUE)
multi3b <- nnet::multinom(catvote ~ age, 
  data = vote,  subset = age > 30, 
  weights = poids, trace = FALSE)
# Valeur-p du test de rapport de vraisemblance
pval <- pchisq(q = deviance(multi3a) - deviance(multi3b),
       df = length(coef(multi2a)), 
       lower.tail = FALSE)
```

Si on ajuste plutôt le modèle avec uniquement `age`, la valeur-$p$ est inférieure à $10^{-5}$: le modèle cumulatif à cote proportionnelles ne serait pas une simplification adéquate.

On peut également effectuer des tests pour déterminer la significativité

 - la significativité globale (ordonnée à l'origine vs modèle complet)
 - l'effet d'une variable explicative (modèle complet, moins une variable)

# Comparaison des prédictions 

\footnotesize 
Prédictions pour le modèle avec uniquement `age` comme variable explicative.

```{r}
#| label: fig-predmultinom
#| fig-cap: "Probabilités prédites pour chaque modalité selon l'âge."
#| fig-width: 8
#| fig-height: 6
#| out-width: '70%'
#| cache: true
#| eval: true
#| echo: false
#| warning: false
library(MASS)
multi3a <- MASS::polr(
  catvote ~ scale(age, scale = FALSE), 
  data = vote,
  subset = age > 30, 
  weights = poids,
  method = "logistic", 
  Hess = TRUE)

multi3b <- nnet::multinom(
  catvote ~ scale(age, scale = FALSE), 
  data = vote,
  subset = age > 30, 
  weights = poids,
  Hess = TRUE,
  trace = FALSE)
xpred <- seq(30, 95, by = 0.1) - mean(vote$age)
nobs <- length(xpred)
pred1 <- predict(multi3b, 
                 newdata = data.frame(age = xpred),
                 type = "prob")
pred2 <- predict(multi3a, 
                 newdata = data.frame(age = xpred),
                 type = "prob")
df <- data.frame(
  x = rep(xpred + mean(vote$age), length.out = 6*nobs),
  modele = factor(rep(c("multinomial", "ordinal"), 
                       each = 3*nobs)),
  reponse = factor(c(rep(c("rarement/jamais",
                    "occasionnellement",
                    "toujours"), 
                  each = nobs),
                  rep(c("rarement/jamais",
                    "occasionnellement",
                    "toujours"), 
                  each = nobs))),
  pred = c(pred1, pred2))
                  
ggplot2::ggplot(
  data = df,
  mapping = ggplot2::aes(
    x = x,
    y = pred,
    color = reponse,
    linetype = modele)) + 
  ggplot2::geom_line() +
  ggplot2::labs(y = "probabilité prédite",
       linetype = "modèle",
       color = "vote",
       x = "âge (années)") +
  MetBrewer::scale_color_met_d("Hiroshige") + 
  ggplot2::theme_minimal() +
  ggplot2::theme(legend.position = "bottom") 
```

\normalsize

-->

# Récapitulatif

- La régression multinomiale logistique pour une variable catégorielle à $K$ niveaux est une extension directe de la régression logistique pour données binaires
   - la somme des probabilités vaut 1.
   - il y a $K-1$ équations de cote en termes des variables explicatives,
   - donc le nombre de paramètres croît rapidement.
   
# Récapitulatif

On met beaucoup l'accent sur l'interprétation des coefficients à l'échelle de la cote.

   - rapports de cote = modèle multiplicatif: la cote de catégorie $k$ vs référence est multipliée par $\exp(\beta_{jk})$ pour chaque augmentation de $\mathrm{X}_j$ d'une unité.
   - les coefficients manquants (cote de $Y=k$ vs $Y=l$) peut être déduits par des manipulations algébriques.
    
# Récapitulatif

Les outils usuels d'inférence pour les modèles estimés par maximum de vraisemblance sont applicables.

 - intervalles de confiance (Wald ou vraisemblance profilée)
 - tests de rapport de vraisemblance
 - critères d'information

# Récapitulatif

Côté classification, on va règle générale assigner à la classe la plus probable.

- il existe des équivalents multidimensionnels directs à ce qu'on a couvert (matrice de confusion, taux de bonne classification, gain, etc.) 
- certains concepts (sensibilité, spécificité, fonction d'efficacité du récepteur) ne sont en revanche pas applicables ou n'ont pas d'équivalent.

<!--
# Récapitulatif

Le modèle cumulatif à cote proportionnelle est une simplification du modèle multinomial pour des **données ordinales**.

- On suppose que l'effet des variables est le même pour la cote de la survie de chaque modalité.
- Moins de paramètres, mais postulat à vérifier (via test de rapport de vraisemblance).

-->
