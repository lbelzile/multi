---
title: "Régression logistique"
subtitle: "Analyse multidimensionnelle appliquée"
date: "automne 2022"
author: "Léo Belzile"
institute: "HEC Montréal"
format: beamer
navigation: empty
colortheme: Flip
innertheme: Flip
outertheme: Flip
themeoptions: "bullet=circle, topline=true, shadow=false"
beamerarticle: false
pdf-engine: lualatex
cache: true
code-line-numbers: true
fig-align: 'center'
mainfont: "D-DIN"
mathfont: 'Latin Modern Math'
sansfont: 'Latin Modern Sans'
keep-tex: true
include-in-header: 
      text: |
        \usepackage{tabu}
        \usepackage{mathtools}
        \usepackage{mathrsfs}
---

# Rappel

La régression logistique spécifie un modèle pour la probabilité de succès 
$$p = \Pr(Y=1 \mid \mathbf{X}) = \frac{1}{1+\exp(-\eta)}$$
où $\eta = \beta_0 + \cdots + \beta_p \mathrm{X}_p$.

# Prédiction

En substituant l'estimation $\widehat{\beta}_0, \ldots, \widehat{\beta}_p$, on calcule 

- le prédicteur linéaire $\widehat{\eta}_i$ et
- la probabilité de succès $\widehat{p}_i$

pour chaque ligne de la base de données.

# Classification de base

Choisir un point de coupure $c$:

- si $\widehat{p} < c$, on assigne $\widehat{Y}=0$.
- si $\widehat{p} \geq c$, on assigne $\widehat{Y}=1$.

- Un point de coupure de $c=0.5$ revient à assigner l'observation à la classe (catégorie) la plus probable.
- Si $c=0$, on catégorise toutes les observations en succès avec $\widehat{Y}_i=1$ $(i=1, \ldots, n)$.

# Qualité de l'ajustement

L'erreur quadratique pour une variable binaire est
$$(Y-\widehat{Y})^2 = \begin{cases} 1, & Y \neq \widehat{Y}; \\0, & Y = \widehat{Y}.\end{cases}$$
et donc on obtient le **taux de mauvaise classification** si on calcule la moyenne.

Plus le taux de mauvaise classification est petit, meilleure est la capacité prédictive du modèle.

# Estimation de la performance du modèle

Utiliser les mêmes données pour l'ajustement et l'estimation
de la performance n'est (toujours) pas recommandé.

Plutôt, considérer

- la validation croisée
- la division de l'échantillon

# Base de données marketing

On considère un modèle pour `yachat`, le fait qu'une personne achète suite à l'envoi d'un catalogue

```{r, echo = TRUE, eval = TRUE}
data(dbm, package = "hecmulti")
formule <- formula("yachat ~ x1 + x2 + x3 +
                x4 + x5 + x6 + x7 + x8 + x9 + x10")
dbm_class <- dbm |>
  dplyr::filter(test == 0) |>
  # pour caret, convertir 0/1 en facteurs
  dplyr::mutate(yachat = factor(yachat))
```

# Estimation avec validation croisée

On utilise la fonction `train` du paquet `caret`, avec le modèle linéaire généralisé

```{r, warning=FALSE, message=FALSE, echo = TRUE, eval = TRUE}
set.seed(202209)
cv_glm <- 
  caret::train(form = formule,
             data = dbm_class,
             method = "glm",
             family = binomial(link = "logit"),
             trControl = caret::trainControl(
               method = "cv",
               number = 10))
```


# Prédictions


```{r}
#| label: fig-classification0
#| echo: false
#| eval: true
#| cache: true
#| fig-cap: "Répartition des probabilités de succès prédites par validation croisée."
data(dbm, package = 'hecmulti')
# Transformer les variables catégorielles en facteurs
# Ne conserver que l'échantillon d'apprentissage
train <- dbm[(dbm$test == 0),]
# Formule pour la moyenne du modèle logistique
form <- formula("yachat ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10")
# Créer un conteneur pour les probabilités
n <- nrow(train)
loocv_prob <- rep(0, n)
# Calculer la prédiction avec validation croisée (n groupes)
# On retourne la probabilité de façon à obtenir le taux de mauvaise classification
# la sensibilité et la spécificité pour différents seuils
for(i in seq_len(n)){
   mod <- glm(data = train, 
              formula = form, 
              family=binomial(link="logit"),
              subset = -i)
   loocv_prob[i] <- predict(mod, newdata = train[i,], type = "response")
}
# Histogramme des probabilités prédites par validation croisée avec n groupes
hist(loocv_prob, 
     breaks = 25, 
     xlab = "Probabilité d'achat prédite", 
     ylab = "densité", main = "")
#  Modèle complet et valeurs prédites
train_prob <- fitted(glm(data = train, 
                         formula = form, 
                         family=binomial), 
                     type = "response") 

perfo <- function(prob, resp, plot = FALSE){
   # VRAI == 1, FAUX == 0
   cuts <- seq(from = 0.005, to = 0.995, by = 0.005)
   tab <- data.frame(coupe = cuts,
      t(sapply(cuts, function(cut){
   nsucces <- sum(resp == 1)
   nechec <- length(resp) - nsucces
   n <- length(resp)
   predy <- ifelse(prob >= cut, 1, 0) 
   c1 <- sum(predy & resp) # Y=1, Yhat=1
   c0 <- sum(!predy & !resp) # Y=0, Yhat=0
   i1 <- sum(!predy & resp) # Y=1, Yhat=0
   i0 <- sum(predy & !resp) # Y=0, Yhat=1
   c(c1 = c1, 
     c0 = c0, 
     i0 = i0,
     i1 = i1,      
     pcorrect = 100*(c0+c1)/n, 
     sensi = 100*c1/(c1+i1), # Y=1 & Yhat=1 / # Y=1
     speci = 100*c0/(c0+i0), # Y=0 & Yhat=0 / # Y=0
     fpos = 100*i0/(c1+i0), # Y=0 & Yhat=1 / # Yhat=1
     fneg = 100*i1/(c0+i1)) # Y=1 & Yhat=0 / # Yhat=0
   })))
   if(plot){
     plot(c(1,1-tab$speci/100,0), c(1,tab$sensi/100,0), type = "l", pty = "s", bty = "l", 
          xlab = "1-spécificité", 
          ylab = "sensibilité", 
          main ="Fonction d'efficacité du récepteur (ROC)",
          panel.first = abline(a=0,b=1), 
          ylim = c(0,1), xlim = c(0,1), yaxs = "i", xaxs = "i")
   }
   invisible(list(cut = tab[which.max(tab$pcorrect),"coupe"],
        confusion = matrix(tab[which.max(tab$pcorrect), c(2,5,4,3)], nrow = 2, ncol = 2),
        table = tab))
   
}
# Performance du modèle avec données d'apprentissage
perfo0 <- perfo(prob = train_prob, resp = train$yachat)
perfo1 <- perfo(prob = loocv_prob, resp = train$yachat)
```

# Performance

On peut varier le point de coupure et regarder pour chaque valeur de $c$ la classification résultante.


```{r}
#| eval: false
#| echo: true
# predict retourne une matrice n x 2 
# avec [P(Y=1), P(Y=0)]
predprob <- predict(cv_glm, type = "prob")[,1]
# Tableau de la performance
hecmulti::perfo_logistique(
  prob = predprob,
  resp = with(dbm, yachat[test == 0]))
```

# Matrice de confusion

On peut classer les observations dans un tableau pour un point de coupure donné.

```{r}
#| label: tbl-confumat
#| eval: true
#| echo: false
#| tbl-cap: "Matrice de confusion avec point de coupure 0.465."
confumat <- perfo1$confusion
rownames(confumat) <- c("\\(\\widehat{Y}=1\\)","\\(\\widehat{Y}=0\\)")
colnames(confumat) <- c("\\(Y=1\\)","\\(Y=0\\)")
knitr::kable(x = confumat, 
                align = "r",
                escape = FALSE,
                booktabs = TRUE,
             format = "latex")
```
