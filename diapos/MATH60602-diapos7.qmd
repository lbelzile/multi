---
title: "Régression logistique: classification"
subtitle: "Analyse multidimensionnelle appliquée"
date: "automne 2022"
author: "Léo Belzile"
institute: "HEC Montréal"
format: beamer
navigation: empty
colortheme: Flip
innertheme: Flip
outertheme: Flip
themeoptions: "bullet=circle, topline=true, shadow=false"
beamerarticle: false
pdf-engine: lualatex
cache: true
code-line-numbers: true
fig-align: 'center'
mainfont: "D-DIN"
mathfont: 'Latin Modern Math'
sansfont: 'Latin Modern Sans'
keep-tex: true
include-in-header: 
      text: |
        \usepackage{tabu}
        \usepackage{mathtools}
        \usepackage{mathrsfs}
---

# Rappel

La régression logistique spécifie un modèle pour la probabilité de succès 
$$p = \Pr(Y=1 \mid \mathbf{X}) = \frac{1}{1+\exp(-\eta)}$$
où $\eta = \beta_0 + \cdots + \beta_p \mathrm{X}_p$.

# Prédiction

En substituant l'estimation $\widehat{\beta}_0, \ldots, \widehat{\beta}_p$, on calcule 

- le prédicteur linéaire $\widehat{\eta}_i$ et
- la probabilité de succès $\widehat{p}_i$

pour chaque ligne de la base de données.

# Classification de base

Choisir un point de coupure $c$:

- si $\widehat{p} < c$, on assigne $\widehat{Y}=0$.
- si $\widehat{p} \geq c$, on assigne $\widehat{Y}=1$.

Un point de coupure de $c=0.5$ revient à assigner l'observation à la classe (catégorie) la plus probable.

Qu'arrive t'il si $c=0$ ou $c=1$? **Exemple au tableau**

# Qualité de l'ajustement

L'erreur quadratique pour un problème de classification est
$$(Y-\widehat{Y})^2 = \begin{cases} 1, & Y \neq \widehat{Y}; \\0, & Y = \widehat{Y}.\end{cases}$$
et donc on obtient le **taux de mauvaise classification** si on calcule la moyenne.

Plus le taux de mauvaise classification est petit, meilleure est la capacité prédictive du modèle.

# Base de données marketing

On considère un modèle pour `yachat`, le fait qu'une personne achète suite à l'envoi d'un catalogue.

```{r, echo = TRUE, eval = TRUE}
data(dbm, package = "hecmulti")
formule <- formula("yachat ~ x1 + x2 + x3 +
                x4 + x5 + x6 + x7 + x8 + x9 + x10")
modele <- glm(formule,
              data = dbm, 
              family = binomial,
              subset = test == 0)
```


# Estimation de la performance du modèle

Utiliser les mêmes données pour l'ajustement et l'estimation de la performance n'est (toujours) pas recommandé.

Plutôt, considérer la validation croisée ou la division de l'échantillon.

```{r}
#| eval: false
#| echo: true
set.seed(202209)
# Option par défaut: 
# validation croisée à 10 plis
# 10 répétitions
predprob <- hecmulti::predvc(modele)
```


# Prédictions


```{r}
#| label: figclassification0
#| echo: false
#| eval: true
#| cache: true
#| fig-width: 8
#| fig-height: 6
#| out-width: '80%'
#| fig-align: 'center'
data(dbm, package = 'hecmulti')
# Transformer les variables catégorielles en facteurs
# Ne conserver que l'échantillon d'apprentissage
train <- dbm[(dbm$test == 0),]
# Formule pour la moyenne du modèle logistique
form <- formula("yachat ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10")
mod <- glm(data = train,
           formula = form, 
           family = binomial)
# Créer un conteneur pour les probabilités
set.seed(60602)
prob <- hecmulti::predvc(mod)
# Histogramme des probabilités prédites par validation croisée avec n groupes
library(ggplot2)
ggplot(data = data.frame(x = prob),
       aes(x = x)) +
  geom_histogram() + 
  labs(x = "probabilité d'achat prédite", 
       y = "") +
  theme_minimal()
#  Modèle complet et valeurs prédites
train_prob <- fitted(glm(data = train, 
                         formula = form, 
                         family=binomial), 
                     type = "response") 

perfo <- function(prob, resp, plot = FALSE){
   # VRAI == 1, FAUX == 0
   cuts <- seq(from = 0.005, to = 0.995, by = 0.005)
   tab <- data.frame(coupe = cuts,
      t(sapply(cuts, function(cut){
   nsucces <- sum(resp == 1)
   nechec <- length(resp) - nsucces
   n <- length(resp)
   predy <- ifelse(prob >= cut, 1, 0) 
   c1 <- sum(predy & resp) # Y=1, Yhat=1
   c0 <- sum(!predy & !resp) # Y=0, Yhat=0
   i1 <- sum(!predy & resp) # Y=1, Yhat=0
   i0 <- sum(predy & !resp) # Y=0, Yhat=1
   c(c1 = c1, 
     c0 = c0, 
     i0 = i0,
     i1 = i1,      
     pcorrect = 100*(c0+c1)/n, 
     sensi = 100*c1/(c1+i1), # Y=1 & Yhat=1 / # Y=1
     speci = 100*c0/(c0+i0), # Y=0 & Yhat=0 / # Y=0
     fpos = 100*i0/(c1+i0), # Y=0 & Yhat=1 / # Yhat=1
     fneg = 100*i1/(c0+i1)) # Y=1 & Yhat=0 / # Yhat=0
   })))
   if(plot){
     plot(c(1,1-tab$speci/100,0), c(1,tab$sensi/100,0), type = "l", pty = "s", bty = "l", 
          xlab = "1-spécificité", 
          ylab = "sensibilité", 
          main ="Fonction d'efficacité du récepteur (ROC)",
          panel.first = abline(a=0,b=1), 
          ylim = c(0,1), xlim = c(0,1), yaxs = "i", xaxs = "i")
   }
   invisible(list(cut = tab[which.max(tab$pcorrect),"coupe"],
        confusion = matrix(tab[which.max(tab$pcorrect), c(2,5,4,3)], nrow = 2, ncol = 2),
        table = tab))
   
}
# Performance du modèle avec données d'apprentissage
perfo0 <- perfo(prob = train_prob, resp = train$yachat)
perfo1 <- perfo(prob = prob, resp = train$yachat)
```

\footnotesize 

Répartition des probabilités de succès prédites par validation croisée.

\normalsize 

# Choix d'un point de coupure.

On peut faire varier le point de coupure et choisir celui qui maximise le taux de bonne classification, $\widehat{\Pr}(Y = \widehat{Y})$.

```{r}
#| fig-width: 8
#| fig-height: 4
#| out-width: '80%'
#| fig-align: 'center'
library(ggplot2)
ggplot(data = perfo1$table,
       aes(x = coupe, 
           y = 100 - pcorrect)) +
  geom_line() +
  geom_vline(xintercept = 0.465, linetype = "dashed", alpha = 0.5) + 
  labs(x = "point de coupure",
       y = "",
       subtitle = "taux de mauvaise classification (pourcentage)") +
  scale_x_continuous(expand = c(0.01,0.01),
                     breaks = c(0,0.25,0.5,0.75,1),
                     labels = c("0","0.25","0.5","0.75","1")) + 
  theme_classic()
```

Avec $c=0.465$, on obtient un taux de mauvaise classification de 15.3\%.

# Performance et classification



```{r}
#| eval: false
#| echo: true
classif <- with(dbm, yachat[test == 0])
# Tableau de la performance
hecmulti::perfo_logistique(
  prob = predprob,
  resp = classif)
```

# Matrice de confusion

On peut classifier les observations dans un tableau pour un point de coupure donné.

```{r}
#| label: tbl-confumat
#| eval: true
#| echo: false
#| tbl-cap: "Matrice de confusion avec point de coupure 0.465."
confumat <- perfo1$confusion
rownames(confumat) <- c("\\(\\widehat{Y}=1\\)","\\(\\widehat{Y}=0\\)")
colnames(confumat) <- c("\\(Y=1\\)","\\(Y=0\\)")
knitr::kable(x = confumat, 
                align = "r",
                escape = FALSE,
                booktabs = TRUE,
             format = "latex")
```


# Classification et mesures de performance

\footnotesize 

Les estimés empiriques sont simplement obtenus en calculant les rapports du nombre d'observations dans chaque classe.

\normalsize 

```{r}
#| label: tableconfumat2
#| eval: true
#| echo: false
confumat <- perfo1$confusion
rownames(confumat) <- c("\\(\\widehat{Y}=1\\)","\\(\\widehat{Y}=0\\)")
colnames(confumat) <- c("\\(Y=1\\)","\\(Y=0\\)")
confumat_th <- confumat
confumat_th[1:4] <- c("VP","FN","FP","VN")
tab1 <- knitr::kable(x = confumat,
                align = "r",
                escape = FALSE,
                booktabs = TRUE,
             format = "latex")
tab2 <- knitr::kable(x = confumat_th,
                align = "r",
                escape = FALSE,
                booktabs = TRUE,
             format = "latex")
knitr::kables(list(tab1, tab2))

```


- La **sensibilité** est le taux de succès correctement classés, $\Pr(Y=1, \widehat{Y}=1 \mid Y=1)$, soit $\mathsf{VP}/(\mathsf{VP}+\mathsf{FN})$.
- La **spécificité** est le taux d'échecs correctement classés, $\Pr(Y=0, \widehat{Y}=0 \mid Y=0)$, soit $\mathsf{VN}/(\mathsf{VN}+\mathsf{FP})$.
- Le taux de **faux positifs** est $\Pr(Y=0, \widehat{Y}=1 \mid \widehat{Y}=1)$.
- Le taux de **faux négatifs** est $\Pr(Y=1, \widehat{Y}=0 \mid \widehat{Y}=0)$.

# Matrice de gain

Il est également possible d'assigner un poids différent à chaque événement selon le scénario et chercher à maximiser le gain.


```{r}
#| label: tbl-tableconfumat4
#| eval: true
#| echo: false
#| tbl-cap: "Matrice de gain (cas général)"
confumat_tbclassif <- confumat
confumat_tbclassif[1:4] <- c("$c_{11}$","$c_{01}$","$c_{10}$","$c_{00}$")
tab1 <- knitr::kable(x = confumat_tbclassif,
                align = "r",
                escape = FALSE,
                booktabs = TRUE,
             format = "latex")
tab1

```



On calcule le gain en faisant la somme des entrées fois les poids, soit $$\textsf{gain} = c_{11}\mathsf{VP} + c_{10}\mathsf{FP} + c_{01}\mathsf{FN} + c_{00}\mathsf{VN}.$$

# Gain pour taux de bonne classification

Si on cherche à maximiser le taux de bonne classification, cela revient à assigner les poids suivants.


```{r}
#| label: tbl-tableconfumat3
#| tbl-cap: "Matrice de gain pour le taux de bonne classification."
#| eval: true
#| echo: false
#| fig-align: 'center'
confumat_tbclassif <- confumat
confumat_tbclassif[1:4] <- c("$1$","$0$","$0$","$1$")
tab1 <- knitr::kable(x = confumat_tbclassif,
                align = "r",
                escape = FALSE,
                booktabs = TRUE,
             format = "latex",)
tab1

```

# Coûts et bénéfices du ciblage marketing



- Si on n'envoie pas de catalogue, notre gain est nul. 
- Si on envoie le catalogue 
   - à un client qui n'achète pas, on perd 10$ (le coût de l'envoi). 
   - à un client qui achète, notre revenu net est de 57\$ (revenu moyen moins coût de l'envoi).



```{r}
#| label: tbl-dbm-ymontant-apprentissage
#| echo: false
#| eval: true
#| tbl-cap: "Statistiques descriptives des montants d'achats pour la base de données marketing."
data(dbm, package = "hecmulti")
dbm |>
  dplyr::filter(test == 0,
                  !is.na(ymontant))  |>
  dplyr::summarize("n" = length(ymontant), 
            "moyenne" = round(mean(ymontant),2), 
            "écart-type" =round(sd(ymontant),2), 
            "minimum" = min(ymontant), 
            "maximum" = max(ymontant)) |>
knitr::kable(booktabs = TRUE) |>
    kableExtra::kable_styling(full_width = TRUE)
```
\footnotesize 
Statistiques descriptives des montants d'achats pour la base de données marketing.

\normalsize


```{r}
#| label: tbl-tableconfumat5
#| eval: true
#| echo: false
#| tbl-cap: "Matrice de gain pour ciblage marketing."
confumat_tbclassif <- confumat
confumat_tbclassif[1:4] <- c("$57$","$0$","$-10$","$0$")
knitr::kable(x = confumat_tbclassif,
                align = "r",
                escape = FALSE,
                booktabs = TRUE,
             format = "latex")
```


# Point de coupure avec gain

```{r}
#| label: fig-coupure-pondere-fake
#| eval: false
#| echo: true
#| cache: true
#| fig-cap: "Estimation du gain moyen en fonction du point de coupure pour l'exemple de base de données marketing."
formule = formula(yachat ~ x1 + x2 + x3 +
                    x4 + x5 + x6 + x7 + 
                    x8 + x9 + x10)
modele <- glm(formule, 
              family = binomial, 
              data = hecmulti::dbm)
coupe <- hecmulti::select_pcoupe(
  modele = modele, 
  c00 = 0, 
  c01 = 0, 
  c10 = -10, 
  c11 = 57,
  plot = TRUE)
```

\footnotesize


La fonction `select_pcoupe` estime le gain pour différents points de coupures, avec probabilités estimées par validation croisée avec `ncv` groupes, répétée `nrep` fois.

\normalsize

# Calcul du gain


```{r}
#| label: fig-coupure-pondere
#| eval: true
#| echo: false
#| cache: true
#| fig-align: 'center'
#| out-width: '80%'
#| fig-width: 6
#| fig-height: 4
#| fig-cap: "Estimation du gain moyen en fonction du point de coupure pour l'exemple de base de données marketing."
formule = formula(yachat ~ x1 + x2 + x3 +
                    x4 + x5 + x6 + x7 + 
                    x8 + x9 + x10)
modele <- glm(formule, 
              family = binomial, 
              data = hecmulti::dbm)
coupe <- hecmulti::select_pcoupe(
  modele = modele, 
  c00 = 0, 
  c01 = 0, 
  c10 = -10, 
  c11 = 57,
  plot = TRUE)
```



# Point de coupure optimal et explication

Dans l'exemple, le point de coupure qui maximise le gain est `r coupe$optim`. Avec ce point de coupure, on estime que 

- le taux de bonne classification est de `r round(perfo1$table[24,"pcorrect"], 2)` 
- la sensibilité est de `r round(perfo1$table[24,"sensi"], 2)`. 

Ainsi, on va détecter environ `r round(perfo1$table[24,"sensi"],2)`\% des clients qui achètent. 

Il est coûteux de rater un client potentiel, donc la stratégie optimale est d'envoyer le catalogue à plus de clients quitte à ce que plusieurs d'entre eux n'achètent rien. 


# Fonction d'efficacité du récepteur

Graphique de la sensibilité en fonction de un moins la spécificité, en faisant varier le point de coupure, souvent appelé courbe ROC (de l'anglais *receiver operating characteristic*).

La fonction `hecmulti::courbe_roc` permet de tracer la courbe et de calculer l’aire sous la courbe. 

```{r}
#| eval: false
#| echo: true
roc <- hecmulti::courbe_roc(
  resp = classif,
  prob = predprob,
  plot = TRUE)
print(roc)
## Pour extraire l'aire sous la courbe, roc$aire
```


# Courbe ROC

```{r}
#| eval: true
#| echo: false
#| out-width: '80%'
#| fig-align: 'center'
predprob <- predict(cv_glm, type = "prob")[,2]
classif <- with(dbm, yachat[test == 0])
roc <- hecmulti::courbe_roc(
  resp = classif,
  prob = predprob,
  plot = TRUE)
## Pour extraire l'aire sous la courbe, roc$aire
```

# Aire sous la courbe

- Plus la courbe se rapproche de (0, 1) (coin supérieur gauche), meilleure est la classification.
- Autrement dit, plus l'aire sous la courbe est près de 1, mieux c’est.
- Une aire sous la courbe de 0.5 (ligne diagonale) correspond à la performance d'une allocation aléatoire.

# Courbe lift

À quelle point notre modèle est meileur qu'une assignation aléatoire?

- Ordonner les probabilités de succès estimées par le modèle, $\widehat{p}$, en ordre croissant.
- Regarder quelle pourcentage de ces derniers seraient bien classifiés (le nombre de vrais positifs sur le nombre de succès).
La référence est la ligne diagonale, qui correspond à une détection aléatoire.

# Code pour produire la courbe lift 

```{r}
#| label: figcourbe-lift
#| eval: false
#| echo: true
tab_lift <- hecmulti::courbe_lift(
  prob = predprob,
  resp = classif, 
  plot = TRUE)
tab_lift
```


# Tableau du lift

```{r}
#| label: tbl-lift
#| echo: false
#| eval: true
#| tbl-cap: "Tableau du lift (déciles)."
knitr::kable(tab_lift[,-1], 
             booktabs = TRUE,
             digits = 2,
             col.names = c("hasard", 
                           "modèle", 
                           "lift"),
             format = "latex") 
```

\footnotesize 
Si on classifiait comme acheteurs les 10\% qui ont la plus forte probabilité estimée d'achat, on détecterait 81 des 210 clients.

Le lift est le nombre détecté par le modèle sur la proportion détectée par hasard.
\normalsize


# Courbe lift

```{r}
#| label: figcourbe-lift-pr
#| eval: true
#| echo: false
tab_lift <- hecmulti::courbe_lift(
  prob = predprob,
  resp = classif, 
  plot = TRUE)
```


# Calibration du modèle

Certains modèles sont trop confiants dans leurs prédictions (surajustement).


une statistique simple proposée par [Spiegelhalter (1986)]( https://doi.org/10.1002/sim.4780050506) peut être utile à cette fin. Pour une variable Bernoulli $Y \in \{0,1\}$, l'erreur quadratique moyenne s'écrit
\begin{align*}
\overline{B} &= \underset{\text{erreur quadratique moyenne}}{\frac{1}{n} \sum_{i=1}^n (Y_i-p_i)^2}
\\&=\underset{\text{manque de calibration}}{\frac{1}{n} \sum_{i=1}^n(Y_i-p_i)(1-2p_i)} + \underset{\text{variabilité}}{\frac{1}{n} \sum_{i=1}^n p_i(1-p_i)}.
\end{align*}

Si notre modèle était parfaitement calibré, $\mathsf{E}_0(Y_i)=p_i$ et $\mathsf{Va}_0(Y_i) = p_i(1-p_i)$.

# Test de Spiegelhalter

On peut calculer la moyenne et la variance attendue sous l'hypothèse nulle et construire une statistique de test [(Spiegelhalter, 1986)]( https://doi.org/10.1002/sim.4780050506). $$Z = \frac{\overline{B} -\mathsf{E}_0(\overline{B})}{\mathsf{sd}_0(\overline{B})}$$ 

Sous l'hypothèse nulle de calibration parfaite, $Z \sim \mathsf{No}(0,1)$ en grand échantillon. 


# Calibration du modèle 

```{r}
#| label: classification
#| eval: true
#| echo: true
hecmulti::calibration(
   prob = predprob, 
   resp = classif)
```

Il n'y a pas de preuve ici que le modèle est mal calibré.

# Récapitulatif

- La classification est une forme d'apprentissage supervisée.
- On peut assigner l'observation à la classe la plus plausible, ou déterminer un point de coupure.
- Si on a un objectif particulier (fonction de gain), on peut optimiser les profits en assignant une importance différente à chaque scénario.
- On peut catégoriser les observations dans une matrice de confusion.

# Récapitulatif

- On s'intéresse à
   - la spécificité (proportion d'échecs correctement classifiés) 
   - la sensibilité (proportion de succès correctement classifiés)
   - le taux de bonne classification
   - le taux de faux positifs ou faux négatifs
- L'aire sous la courbe de la fonction d'efficacité du récepteur (courbe ROC) et le lift donnent une mesure de la qualité des prédictions.

