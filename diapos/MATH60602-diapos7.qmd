---
title: "Régression logistique"
subtitle: "Analyse multidimensionnelle appliquée"
date: "automne 2022"
author: "Léo Belzile"
institute: "HEC Montréal"
format: beamer
navigation: empty
colortheme: Flip
innertheme: Flip
outertheme: Flip
themeoptions: "bullet=circle, topline=true, shadow=false"
beamerarticle: false
pdf-engine: xelatex
cache: true
code-line-numbers: true
fig-align: 'center'
mainfont: "D-DIN"
mathfont: 'Latin Modern Math'
sansfont: 'Latin Modern Sans'
keep-tex: true
include-in-header: 
      text: |
        \usepackage{tabu}
        \usepackage{mathtools}
        \usepackage{mathrsfs}
---

# Rappel

La régression logistique spécifie un modèle pour la probabilité de succès 
$$p = \Pr(Y=1 \mid \mathbf{X}) = \frac{1}{1+\exp(-\eta)}$$
où $\eta = \beta_0 + \cdots + \beta_p \mathrm{X}_p$.

# Prédiction

En substituant l'estimation $\widehat{\beta}_0, \ldots, \widehat{\beta}_p$, on calcule 

- le prédicteur linéaire $\widehat{\eta}_i$ et
- la probabilité de succès $\widehat{p}_i$

pour chaque ligne de la base de données.

# Classification de base

Choisir un point de coupure $c$:

- si $\widehat{p} < c$, on assigne $\widehat{Y}=0$.
- si $\widehat{p} \geq c$, on assigne $\widehat{Y}=1$.

- Un point de coupure de $c=0.5$ revient à assigner l'observation à la classe (catégorie) la plus probable.
- Si $c=0$, on catégorise toutes les observations en succès avec $\widehat{Y}_i=1$ $(i=1, \ldots, n)$.

# Qualité de l'ajustement

L'erreur quadratique pour une variable binaire est
$$(Y-\widehat{Y})^2 = \begin{cases} 1, & Y \neq \widehat{Y}; \\0, & Y = \widehat{Y}.\end{cases}$$
et donc on obtient le **taux de mauvaise classification** si on calcule la moyenne.

Plus le taux de mauvaise classification est petit, meilleure est la capacité prédictive du modèle.

# Estimation de la performance du modèle

Utiliser les mêmes données pour l'ajustement et l'estimation
de la performance n'est (toujours) pas recommandé.

Plutôt, considérer

- la validation croisée,
- la division de l'échantillon.

# Base de données marketing

On considère un modèle pour `yachat`, le fait qu'une personne achète suite à l'envoi d'un catalogue.

```{r, echo = TRUE, eval = TRUE}
data(dbm, package = "hecmulti")
formule <- formula("yachat ~ x1 + x2 + x3 +
                x4 + x5 + x6 + x7 + x8 + x9 + x10")
dbm_class <- dbm |>
  dplyr::filter(test == 0) |>
  # pour caret, convertir 0/1 en facteurs
  dplyr::mutate(yachat = factor(yachat))
```

# Estimation avec validation croisée

On utilise la fonction `train` du paquet `caret`, avec le modèle linéaire généralisé.

```{r, warning=FALSE, message=FALSE, echo = TRUE, eval = TRUE}
set.seed(202209)
cv_glm <- 
  caret::train(form = formule,
             data = dbm_class,
             method = "glm",
             family = binomial(link = "logit"),
             trControl = caret::trainControl(
               method = "cv",
               number = 10))
```


# Prédictions


```{r}
#| label: figclassification0
#| echo: false
#| eval: true
#| cache: true
#| fig-width: 8
#| fig-height: 4
#| out-width: '80%'
#| fig-align: 'center'
data(dbm, package = 'hecmulti')
# Transformer les variables catégorielles en facteurs
# Ne conserver que l'échantillon d'apprentissage
train <- dbm[(dbm$test == 0),]
# Formule pour la moyenne du modèle logistique
form <- formula("yachat ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10")
# Créer un conteneur pour les probabilités
n <- nrow(train)
loocv_prob <- rep(0, n)
# Calculer la prédiction avec validation croisée (n groupes)
# On retourne la probabilité de façon à obtenir le taux de mauvaise classification
# la sensibilité et la spécificité pour différents seuils
for(i in seq_len(n)){
   mod <- glm(data = train, 
              formula = form, 
              family=binomial(link="logit"),
              subset = -i)
   loocv_prob[i] <- predict(mod, newdata = train[i,], type = "response")
}
# Histogramme des probabilités prédites par validation croisée avec n groupes
hist(loocv_prob, 
     breaks = 25, 
     xlab = "Probabilité d'achat prédite", 
     ylab = "densité", main = "")
#  Modèle complet et valeurs prédites
train_prob <- fitted(glm(data = train, 
                         formula = form, 
                         family=binomial), 
                     type = "response") 

perfo <- function(prob, resp, plot = FALSE){
   # VRAI == 1, FAUX == 0
   cuts <- seq(from = 0.005, to = 0.995, by = 0.005)
   tab <- data.frame(coupe = cuts,
      t(sapply(cuts, function(cut){
   nsucces <- sum(resp == 1)
   nechec <- length(resp) - nsucces
   n <- length(resp)
   predy <- ifelse(prob >= cut, 1, 0) 
   c1 <- sum(predy & resp) # Y=1, Yhat=1
   c0 <- sum(!predy & !resp) # Y=0, Yhat=0
   i1 <- sum(!predy & resp) # Y=1, Yhat=0
   i0 <- sum(predy & !resp) # Y=0, Yhat=1
   c(c1 = c1, 
     c0 = c0, 
     i0 = i0,
     i1 = i1,      
     pcorrect = 100*(c0+c1)/n, 
     sensi = 100*c1/(c1+i1), # Y=1 & Yhat=1 / # Y=1
     speci = 100*c0/(c0+i0), # Y=0 & Yhat=0 / # Y=0
     fpos = 100*i0/(c1+i0), # Y=0 & Yhat=1 / # Yhat=1
     fneg = 100*i1/(c0+i1)) # Y=1 & Yhat=0 / # Yhat=0
   })))
   if(plot){
     plot(c(1,1-tab$speci/100,0), c(1,tab$sensi/100,0), type = "l", pty = "s", bty = "l", 
          xlab = "1-spécificité", 
          ylab = "sensibilité", 
          main ="Fonction d'efficacité du récepteur (ROC)",
          panel.first = abline(a=0,b=1), 
          ylim = c(0,1), xlim = c(0,1), yaxs = "i", xaxs = "i")
   }
   invisible(list(cut = tab[which.max(tab$pcorrect),"coupe"],
        confusion = matrix(tab[which.max(tab$pcorrect), c(2,5,4,3)], nrow = 2, ncol = 2),
        table = tab))
   
}
# Performance du modèle avec données d'apprentissage
perfo0 <- perfo(prob = train_prob, resp = train$yachat)
perfo1 <- perfo(prob = loocv_prob, resp = train$yachat)
```

\footnotesize 

Répartition des probabilités de succès prédites par validation croisée.

\normalsize 

# Performance

On peut varier le point de coupure et regarder pour chaque valeur de $c$ la classification résultante.


```{r}
#| eval: false
#| echo: true
# predict retourne une matrice n x 2 
# avec [P(Y=0), P(Y=1)]
predprob <- predict(cv_glm, type = "prob")[,2]
classif <- with(dbm, yachat[test == 0])
# Tableau de la performance
hecmulti::perfo_logistique(
  prob = predprob,
  resp = classif)
```

# Matrice de confusion

On peut classer les observations dans un tableau pour un point de coupure donné.

```{r}
#| label: tbl-confumat
#| eval: true
#| echo: false
#| tbl-cap: "Matrice de confusion avec point de coupure 0.465."
confumat <- perfo1$confusion
rownames(confumat) <- c("\\(\\widehat{Y}=1\\)","\\(\\widehat{Y}=0\\)")
colnames(confumat) <- c("\\(Y=1\\)","\\(Y=0\\)")
knitr::kable(x = confumat, 
                align = "r",
                escape = FALSE,
                booktabs = TRUE,
             format = "latex")
```


# Classification et mesures de performance

\footnotesize 

Les estimés empiriques sont simplement obtenus en calculant les rapports du nombre d'observations dans chaque classe.

\normalsize 

```{r}
#| label: tableconfumat2
#| eval: true
#| echo: false
confumat <- perfo1$confusion
rownames(confumat) <- c("\\(\\widehat{Y}=1\\)","\\(\\widehat{Y}=0\\)")
colnames(confumat) <- c("\\(Y=1\\)","\\(Y=0\\)")
confumat_th <- confumat
confumat_th[1:4] <- c("VP","FN","FP","VN")
tab1 <- knitr::kable(x = confumat,
                align = "r",
                escape = FALSE,
                booktabs = TRUE,
             format = "latex")
tab2 <- knitr::kable(x = confumat_th,
                align = "r",
                escape = FALSE,
                booktabs = TRUE,
             format = "latex")
knitr::kables(list(tab1, tab2))

```


- La **sensibilité** est le taux de succès correctement classés, $\Pr(Y=1, \widehat{Y}=1 \mid Y=1)$, soit $\mathsf{VP}/(\mathsf{VP}+\mathsf{FN})$.
- La **spécificité** est le taux d'échecs correctement classés, $\Pr(Y=0, \widehat{Y}=0 \mid Y=0)$, soit $\mathsf{VN}/(\mathsf{VN}+\mathsf{FP})$.
- Le taux de **faux positifs** est $\Pr(Y=0, \widehat{Y}=1 \mid \widehat{Y}=1)$.
- Le taux de **faux négatifs** est $\Pr(Y=1, \widehat{Y}=0 \mid \widehat{Y}=0)$.

# Choix d'un point de coupure.

On peut faire varier le point de coupure et choisir celui qui minimise le  taux de mauvaise classification, $(\mathsf{FP} + \mathsf{FN})/n$.

Ici, avec $c=0.465$, on obtient 15.3\%.

```{r}
#| fig-width: 8
#| fig-height: 4
#| out-width: '80%'
#| fig-align: 'center'
library(ggplot2)
ggplot(data = perfo1$table,
       aes(x = coupe, 
           y = 100 - pcorrect)) +
  geom_line() +
  geom_vline(xintercept = 0.465, linetype = "dashed", alpha = 0.5) + 
  labs(x = "point de coupure",
       y = "",
       subtitle = "taux de mauvaise classification (pourcentage)") +
  scale_x_continuous(expand = c(0.01,0.01),
                     breaks = c(0,0.25,0.5,0.75,1),
                     labels = c("0","0.25","0.5","0.75","1")) + 
  theme_classic()
```

# Fonction d'efficacité du récepteur

Graphique de la sensibilité en fonction de un moins la spécificité, en faisant varier le point de coupure, souvent appelé courbe ROC (de l'anglais *receiver operating characteristic*).

La fonction `hecmulti::courbe_roc` permet de tracer la courbe et de calculer l’aire sous la courbe. 

```{r}
#| eval: false
#| echo: true
roc <- hecmulti::courbe_roc(
  resp = classif,
  prob = predprob,
  plot = TRUE)
print(roc)
## Pour extraire l'aire sous la courbe, roc$aire
```


# Courbe ROC

```{r}
#| eval: true
#| echo: false
#| out-width: '80%'
#| fig-align: 'center'
predprob <- predict(cv_glm, type = "prob")[,2]
classif <- with(dbm, yachat[test == 0])
roc <- hecmulti::courbe_roc(
  resp = classif,
  prob = predprob,
  plot = TRUE)
## Pour extraire l'aire sous la courbe, roc$aire
```

# Aire sous la courbe

- Plus la courbe se rapproche de (0, 1) (coin supérieur gauche), meilleure est la classification.
- Autrement dit, plus l'aire sous la courbe est près de 1, mieux c’est.
- Une aire sous la courbe de 0.5 (ligne diagonale) correspond à la performance d'une allocation aléatoire.

# Courbe lift

À quelle point notre modèle est meileur qu'une assignation aléatoire?

- Ordonner les probabilités de succès estimées par le modèle, $\widehat{p}$, en ordre croissant.
- Regarder quelle pourcentage de ces derniers seraient bien classifiés (le nombre de vrais positifs sur le nombre de succès).
La référence est la ligne diagonale, qui correspond à une détection aléatoire.

# Code pour produire la courbe lift 

```{r}
#| label: figcourbe-lift
#| eval: false
#| echo: true
tab_lift <- hecmulti::courbe_lift(
  prob = 1-predprob,
  resp = classif, 
  plot = TRUE)
tab_lift
```

# Courbe lift

```{r}
#| label: figcourbe-lift-pr
#| eval: true
#| echo: false
tab_lift <- hecmulti::courbe_lift(
  prob = 1-predprob,
  resp = classif, 
  plot = TRUE)
tab_lift
```


# Tableau du lift

```{r}
#| label: tbl-lift
#| echo: false
#| eval: true
#| tbl-cap: "Tableau du lift (déciles)."
knitr::kable(tab_lift, 
             booktabs = TRUE,
             digits = 2,
             format = "latex") |>
  kableExtra::kable_styling(full_width = TRUE)
```

\footnotesize 
Si on classifiait comme acheteurs les 10\% qui ont la plus forte probabilité estimée d'achat, on détecterait 81 des 210 clients.

Le lift est le nombre détecté par le modèle sur proportion au hasard.
\normalsize
