% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  ignorenonframetext,
]{beamer}
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
% Prevent slide breaks in the middle of a paragraph
\widowpenalties 1 10000
\raggedbottom
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{part title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{part title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\usecolortheme{Flip}
\usefonttheme{serif} % use mainfont rather than sansfont for slide text
\useinnertheme{Flip}
\useoutertheme{Flip}
\ifPDFTeX\else  
    % xetex/luatex font selection
  \setmainfont[]{VisbyCF-Medium}
  \setsansfont[]{Latin Modern Sans}
  \setmathfont[]{Latin Modern Math}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\newif\ifbibliography
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
\usepackage{caption}
% Make caption package work with longtable
\makeatletter
\def\fnum@table{\tablename~\thetable}
\makeatother
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{booktabs}
\usepackage{caption}
\usepackage{longtable}
\usepackage{colortbl}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\usepackage{tabu}
\usepackage{mathtools}
\usepackage{mathrsfs}
\makeatletter
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Données manquantes et régression multinomiale},
  pdfauthor={Léo Belzile},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Données manquantes et régression multinomiale}
\subtitle{Analyse multidimensionnelle appliquée}
\author{Léo Belzile}
\date{}
\institute{HEC Montréal}

\begin{document}
\frame{\titlepage}
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[breakable, enhanced, borderline west={3pt}{0pt}{shadecolor}, frame hidden, boxrule=0pt, sharp corners, interior hidden]}{\end{tcolorbox}}\fi

\begin{frame}
\end{frame}

\begin{frame}{Données manquantes}
\protect\hypertarget{donnuxe9es-manquantes}{}
Plusieurs champs d'une base de donnée peuvent être manquants

\begin{itemize}
\tightlist
\item
  non-réponse
\item
  valeurs erronées (erreur d'encodage)
\item
  perte de suivi et censure
\item
  plusieurs versions de formulaires (question optionnelles)
\end{itemize}
\end{frame}

\begin{frame}{Pourquoi s'en préoccuper?}
\protect\hypertarget{pourquoi-sen-pruxe9occuper}{}
La plupart des procédures ne gèrent que les cas complets (toute
observation avec des valeurs manquantes est éliminée).

Les données manquantes réduisent l'information disponible.

Sans traitement adéquat, les estimations seront \textbf{biaisées}.
\end{frame}

\begin{frame}{Références}
\protect\hypertarget{ruxe9fuxe9rences}{}
\begin{itemize}
\tightlist
\item
  van Buuren, S. (2018).
  \href{https://stefvanbuuren.name/fimd/}{\emph{Flexible imputation of
  missing data}}, CRC Press, 2e édition.
\item
  Little, R. et D. Rubin (2019). \emph{Statistical Analysis with Missing
  Data}, Wiley, 3e édition
\item
  Schafer, J. L. (1997). \emph{Analysis of Incomplete Multivariate
  Data}. Chapman \& Hall / CRC.
\end{itemize}

Les valeurs manquantes dans un contexte de prédictions sont couvertes
dans le cours MATH 60600.
\end{frame}

\begin{frame}{Classification des données manquantes (MCAR)}
\protect\hypertarget{classification-des-donnuxe9es-manquantes-mcar}{}
Cas 1: Données manquantes de façon complètement aléatoire (\emph{missing
completely at random})

La probabilité que la valeur soit manquante ne dépend ni de la valeur,
ni de celles des autres variables.

Exemple: questionnaire trop long, la personne ne répond pas à tout (sans
lien avec les questions posées).

Hypothèse souvent irréaliste en pratique.
\end{frame}

\begin{frame}{Classification des données manquantes (MAR)}
\protect\hypertarget{classification-des-donnuxe9es-manquantes-mar}{}
Cas 2: données manquantes de façon aléatoire (\emph{missing at random}):
la probabilité que la valeur soit manquante ne dépend pas de la valeur
\emph{une fois qu'on a contrôlé pour les autres variables}.

Exemple: les hommes sont plus susceptibles dans l'ensemble de divulguer
leur âge que les femmes.
\end{frame}

\begin{frame}{Classification des données manquantes (MNAR)}
\protect\hypertarget{classification-des-donnuxe9es-manquantes-mnar}{}
Cas 3: données manquantes de façon non-aléatoire (\emph{missing not at
random}): la probabilité que la mesure soit manquante dépend de la
valeur elle-même, pas déterminable avec d'autres variables

Exemple: une personne transgenre ne répond pas à la question genre (si
seulement deux choix, homme/femme) et aucune autre question ne se
rattache au genre ou à l'identité sexuelle.
\end{frame}

\begin{frame}{Type de données manquantes}
\protect\hypertarget{type-de-donnuxe9es-manquantes}{}
Comment déterminer le type de données manquantes?

Par exemple, si une personne ne divulgue pas son salaire, est ce qu les
données sont manquantes de manière aléatoire ou non aléatoire?

L'hypothèse pas testable, la réponse dépend du contexte et des variables
auxiliaires disponibles.
\end{frame}

\begin{frame}{Valeur logique}
\protect\hypertarget{valeur-logique}{}
Les données manquantes ont souvent une valeur logique:

\begin{itemize}
\tightlist
\item
  un client qui n'a pas de carte de crédit a un solde de 0!
\end{itemize}

D'où l'importance des validations d'usage et du nettoyage préliminaire
de la base de données.
\end{frame}

\begin{frame}{Types de schémas de données manquantes}
\protect\hypertarget{types-de-schuxe9mas-de-donnuxe9es-manquantes}{}
Matrice \(n \times p\) (observations en lignes, variables en colonnes).

\includegraphics[width=1\textwidth,height=\textheight]{MATH60602-diapos7_files/figure-beamer/unnamed-chunk-1-1.pdf}

\footnotesize

Les cases grises représentent des valeurs manquantes. Illustration
adapté de la Figure 4.1 de van Buuren (2022)
\end{frame}

\begin{frame}{Analyse des cas complet}
\protect\hypertarget{analyse-des-cas-complet}{}
Retirer les observations avec données manquantes pour conserver les cas
complets.

\begin{itemize}
\tightlist
\item
  Valide uniquement pour complètement aléatoire.
\item
  On perd de la précision en utilisant moins d'observations.
\end{itemize}

Méthode par défaut dans les logiciels.
\end{frame}

\begin{frame}{Méthodes d'imputation}
\protect\hypertarget{muxe9thodes-dimputation}{}
Imputation: remplacer les valeurs manquantes par une valeur judicieuse
pour \emph{combler les trous}.

\begin{quote}
\emph{Le concept d'imputation est à la fois séduisant et dangereux}.
(Dempster et Rubin, 1983)
\end{quote}

On distinguera

\begin{itemize}
\tightlist
\item
  l'imputation déterministe (par exemple, remplacer les valeurs
  manquantes par la moyenne) versus aléatoire
\item
  l'imputation simple (une copie) versus multiple (plusieurs
  imputations)
\end{itemize}
\end{frame}

\begin{frame}{Imputation par la moyenne}
\protect\hypertarget{imputation-par-la-moyenne}{}
Dilution de la relation (corrélation) entre variables explicatives.
Réduction de la variabilité.

\begin{figure}

{\centering \includegraphics[width=0.9\textwidth,height=\textheight]{MATH60602-diapos7_files/figure-beamer/unnamed-chunk-2-1.pdf}

}

\end{figure}
\end{frame}

\begin{frame}[fragile]{Imputation aléatoire}
\protect\hypertarget{imputation-aluxe9atoire}{}
Considérons le cas d'une régression logistique pour une variable
explicative binaire.

Plutôt que d'assigner à la classe la plus probable, une prédiction
aléatoire simule une variable 0/1 avec probabilité
\((1-\widehat{p}_i, \widehat{p}_i)\).

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FloatTok{0.3} \CommentTok{\#probabilité de succès}
\FunctionTok{rbinom}\NormalTok{(}\AttributeTok{n =} \DecValTok{15}\NormalTok{, }\AttributeTok{size =} \DecValTok{1}\NormalTok{, }\AttributeTok{prob =}\NormalTok{ pred)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0
\end{verbatim}
\end{frame}

\begin{frame}{Faut-il toujours imputer?}
\protect\hypertarget{faut-il-toujours-imputer}{}
Il faut utiliser son jugement.

Une observation imputée ne remplacera jamais une vraie observation.

\begin{itemize}
\tightlist
\item
  Si la proportion d'observations manquantes est petite (moins de 5\%),
  on pourrait faire une analyse avec les cas complets (et valider au
  besoin en utilisant l'imputation multiple).
\item
  Si la proportion de valeurs manquantes est 30\% et que cette
  proportion baisse à 3\% lorsque vous éliminez quelques variables peu
  importantes pour votre étude, alors procédez à leur élimination.
\end{itemize}
\end{frame}

\begin{frame}{Problèmes de l'imputation simple}
\protect\hypertarget{probluxe8mes-de-limputation-simple}{}
On ne tient pas compte du fait que des valeurs ont été remplacées (on
fait comme si c'était de vraies observations).

On sous-évalue encore une fois la \textbf{variabilité} des données

\begin{itemize}
\tightlist
\item
  les écarts-type des estimations sont trop petits.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Inspection des valeurs manquantes}
\protect\hypertarget{inspection-des-valeurs-manquantes}{}
Il est donc nécessaire d'examiner la configuration des valeurs
manquantes avant de faire quoi que ce soit.

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{data}\NormalTok{(manquantes, }\AttributeTok{package =} \StringTok{\textquotesingle{}hecmulti\textquotesingle{}}\NormalTok{)}
\FunctionTok{summary}\NormalTok{(manquantes)}
\CommentTok{\# Pourcentage de valeurs manquantes}
\FunctionTok{apply}\NormalTok{(manquantes, }\DecValTok{2}\NormalTok{, }\ControlFlowTok{function}\NormalTok{(x)\{}\FunctionTok{mean}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(x))\})}
\CommentTok{\# Voir les configurations de valeurs manquantes}
\FunctionTok{md.pattern}\NormalTok{(manquantes) }\CommentTok{\# graphique diapo suivante}
\end{Highlighting}
\end{Shaded}

\hypertarget{tbl-manquantes-univ}{}
\begin{table}
\caption{\label{tbl-manquantes-univ}Nombre et pourcentage de valeurs manquantes par variable. }\tabularnewline

\centering
\begin{tabular}{llllllll}
\toprule
  & x1 & x2 & x3 & x4 & x5 & x6 & y\\
\midrule
nombre & 192 & 49 & 0 & 184 & 0 & 0 & 0\\
pourcentage & 38.4 & 9.8 & 0 & 36.8 & 0 & 0 & 0\\
\bottomrule
\end{tabular}
\end{table}
\end{frame}

\begin{frame}{Configuration des valeurs manquantes}
\protect\hypertarget{configuration-des-valeurs-manquantes}{}
\begin{figure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{MATH60602-diapos7_files/figure-beamer/fig-manquantes2-1.pdf}

}

\caption{\label{fig-manquantes2}Les noms des variables sont indiquées au
dessus, le nombre total de valeurs manquantes par variable en dessous,
le nombre d'observations pour chaque configuration de valeurs manquantes
à gauche et le nombre de variables avec des valeurs manquantes par
configuration à droitef.}

\end{figure}
\end{frame}

\begin{frame}[fragile]{Imputation multiple}
\protect\hypertarget{imputation-multiple}{}
Valides pour les données manquantes de manière aléatoire et complètement
aléatoires (MAR et MCAR).

\begin{enumerate}
\tightlist
\item
  Procéder à plusieurs imputations \textbf{aléatoires} pour obtenir un
  échantillon complet (\texttt{mice})
\item
  Ajuster le modèle d'intérêt avec chaque échantillon (\texttt{with}).
\item
  Combiner les résultats obtenus (\texttt{pool} et \texttt{summary})
\end{enumerate}

\begin{figure}

{\centering \includegraphics[width=0.7\textwidth,height=\textheight]{figures/donnees_manquantes_workflow.pdf}

}

\end{figure}
\end{frame}

\begin{frame}{Combinaison des résultats}
\protect\hypertarget{combinaison-des-ruxe9sultats}{}
Considérons un seul paramètre \(\theta\) (ex: coefficient d'une
régression) et supposons qu'on procède à \(K\) imputations.

On estime les paramètres du modèle séparément pour chacun des \(K\)
ensembles de données imputés, disons

\begin{itemize}
\tightlist
\item
  \(\widehat{\theta}_k\) pour l'estimation du paramètre \(\theta\) dans
  l'échantillon \(k\) et
\item
  \(\widehat{\sigma}_k^2=\mathsf{Va}(\widehat{\theta}_k)\) pour
  l'estimation de la variance de \(\widehat{\theta}_k\).
\end{itemize}
\end{frame}

\begin{frame}{Estimations}
\protect\hypertarget{estimations}{}
L'estimation finale de \(\theta\), dénotée \(\widehat{\theta}\), est
obtenue tout simplement en faisant la moyenne des estimations de tous
les modèles.

Pour la variance de \(\widehat{\theta}\), on calcule la somme de

\begin{itemize}
\tightlist
\item
  la moyenne des \(K\) variances pour chaque imputation,
  \(\widehat{\sigma}_1^2, \ldots, \widehat{\sigma}_K^2\), appelée
  variance intra-groupe.
\item
  la variance des estimations moyennes,
  \(\widehat{\theta}_1, \ldots, \widehat{\theta}_K\), appelée variance
  inter-groupe.
\end{itemize}

En combinant ces deux sources variabilités, on enfle la variance par
rapport à l'imputation simple
\end{frame}

\begin{frame}{Imputation multiple par équations chaînées (MICE)}
\protect\hypertarget{imputation-multiple-par-uxe9quations-chauxeenuxe9es-mice}{}
Avec \(p\) variables \(X_1, \ldots, X_p\), spécifier un ensemble de
modèles \textbf{conditionnels} pour chaque variable \(X_j\) en fonction
de

\begin{itemize}
\tightlist
\item
  toutes les autres variables, \(\boldsymbol{X}_{-j}\)
\item
  les valeurs observées pour cette variable, \(X_{j, \text{obs}}\)
\end{itemize}

\begin{enumerate}
\tightlist
\item
  Initialisation: remplir les trous avec des données au hasard parmi
  \(X_{j, \text{obs}}\) pour \(X_{j, \text{man}}\)
\item
  À l'itération \(t\), pour chaque variable \(j=1, \ldots, p\), à tour
  de rôle:

  \begin{enumerate}
  [a)]
  \tightlist
  \item
    tirage aléatoire des paramètres \(\phi_j^{(t)}\) du modèle pour
    \(X_{j,\text{man}}\) conditionnel à \(\boldsymbol{X}_{-j}^{(t-1)}\)
    et \(X_{j, \text{obs}}\)
  \item
    échantillonnage de nouvelles observations \(X^{(t)}_{j,\text{man}}\)
    du modèle avec paramètres \(\phi_j^{(t)}\) conditionnel à
    \(\boldsymbol{X}_{-j}^{(t-1)}\) et \(X_{j, \text{obs}}\)
  \end{enumerate}
\item
  Répéter le cycle
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{Imputation multiple avec \texttt{mice}}
\protect\hypertarget{imputation-multiple-avec-mice}{}
\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{library}\NormalTok{(mice)}
\CommentTok{\# Intensif en calcul, réduire "m" si nécessaire}
\NormalTok{impdata }\OtherTok{\textless{}{-}} \FunctionTok{mice}\NormalTok{(}
   \AttributeTok{data =}\NormalTok{ manquantes,}
   \CommentTok{\# argument "method" pour le modèle}
   \CommentTok{\# dépend du type des variables, par ex.}
   \CommentTok{\# régression logistique pour données binaires}
   \AttributeTok{m =} \DecValTok{50}\NormalTok{, }\CommentTok{\# nombre d\textquotesingle{}imputations}
   \AttributeTok{seed =} \DecValTok{60602}\NormalTok{, }\CommentTok{\# germe aléatoire}
   \AttributeTok{printFlag =} \ConstantTok{FALSE}\NormalTok{)}
\CommentTok{\# Extraite une copie (m=1,..., 50) imputée }
\FunctionTok{complete}\NormalTok{(}\AttributeTok{data =}\NormalTok{ impdata, }
         \AttributeTok{action =} \DecValTok{1}\NormalTok{) }\CommentTok{\#no de la copie}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Estimation et combinaison avec \texttt{mice}}
\protect\hypertarget{estimation-et-combinaison-avec-mice}{}
\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{\# ajuste le modèle avec les données imputées}
\NormalTok{adj\_im }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ impdata,}
  \AttributeTok{expr =} \FunctionTok{glm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2 }\SpecialCharTok{+}\NormalTok{ x3 }\SpecialCharTok{+}\NormalTok{ x4 }\SpecialCharTok{+}\NormalTok{ x5 }\SpecialCharTok{+}\NormalTok{ x6,}
             \AttributeTok{family =}\NormalTok{ binomial))}
\CommentTok{\# combinaison des résultats }
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{pool}\NormalTok{(adj\_im)}
\FunctionTok{summary}\NormalTok{(fit)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}{Résultats}
\protect\hypertarget{ruxe9sultats}{}
\begin{itemize}
\tightlist
\item
  Les estimations avec les données complètes ont la plus grande
  incertitude, parce qu'elles utilisent uniquement \(n=180\)
  observations.
\item
  L'imputation multiple donne \(n=500\) observations et prend
  correctement en compte l'incertitude.
\item
  L'imputation simple sous-estime l'incertitude des coefficients.
\end{itemize}

\hypertarget{tbl-manquantsres}{}
\begin{longtable}{rrrrrr}
\caption{\label{tbl-manquantsres}Estimation des coefficients et erreurs type pour quelques paramètres du
modèle. }\tabularnewline

\toprule
\multicolumn{2}{c}{données complètes} & \multicolumn{2}{c}{imputation multiple} & \multicolumn{2}{c}{imputation simple} \\ 
\cmidrule(lr){1-2} \cmidrule(lr){3-4} \cmidrule(lr){5-6}
coef. & err. type & coef. & err. type & coef. & err. type \\ 
\midrule\addlinespace[2.5pt]
$-0.48$ & $0.76$ & $-0.90$ & $0.58$ & $-1.61$ & $0.47$ \\ 
$-0.38$ & $0.77$ & $-0.53$ & $0.59$ & $-0.95$ & $0.46$ \\ 
$-0.84$ & $0.80$ & $-0.76$ & $0.55$ & $-0.89$ & $0.46$ \\ 
$0.09$ & $0.85$ & $-0.58$ & $0.64$ & $-1.15$ & $0.50$ \\ 
$1.19$ & $0.76$ & $-0.03$ & $0.44$ & $-0.16$ & $0.42$ \\ 
\bottomrule
\end{longtable}
\end{frame}

\begin{frame}{Récapitulatif}
\protect\hypertarget{ruxe9capitulatif}{}
\begin{itemize}
\tightlist
\item
  Les données manquantes réduisent la quantité d'information disponible
  et augmentent l'incertitude.
\item
  On ne peut \textbf{pas} les ignorer (étude des cas complets) sans
  biaiser les interprétations et réduire la quantité d'information
  disponible.
\item
  Pour bien capturer l'\textbf{incertitude} et ne pas modifier les
  relations entre variables, il faut utiliser une méthode
  \textbf{aléatoire}.
\item
  Avec l'algorithme MICE, on utilise un modèle conditionnel pour chaque
  variable à tour de rôle
\end{itemize}
\end{frame}

\begin{frame}{Récapitulatif}
\protect\hypertarget{ruxe9capitulatif-1}{}
L'imputation multiple est préférée à l'imputation simple car elle permet
d'estimer l'incertitude sous-jacente en raison des données manquantes.

\begin{itemize}
\tightlist
\item
  On procède à l'imputation plusieurs fois (avec un modèle conditionel,
  prédictions différentes chaque fois)
\item
  on crée plusieurs copies
\item
  ajuste le modèle sur chacune et
\item
  combine les résultats
\end{itemize}

Traitement spécial pour erreurs-type, degrés de liberté, valeurs-\(p\)
et intervalles de confiance.
\end{frame}

\begin{frame}[fragile]{Taux de participation lors des élections
américaines}
\protect\hypertarget{taux-de-participation-lors-des-uxe9lections-amuxe9ricaines}{}
Les
\href{https://github.com/fivethirtyeight/data/tree/master/non-voters}{données}
de cet exemple sont tirées d'un sondage Ipsos réalisé pour le site de
nouvelles \emph{FiveThirtyEight}.

La base de données \texttt{vote} contient 5837 observations avec les
pondérations associées.

Nous allons modéliser l'intention de vote, \texttt{catvote} à l'aide
d'une régression logistique multinomiale. Il y a trois modalités
possible (rarement ou jamais, occasionnellement et toujours).
\end{frame}

\begin{frame}{Analyse exploratoire}
\protect\hypertarget{analyse-exploratoire}{}
\begin{figure}

{\centering \includegraphics[width=0.8\textwidth,height=\textheight]{MATH60602-diapos7_files/figure-beamer/fig-multinom_means-Ipsos-1.pdf}

}

\caption{\label{fig-multinom_means-Ipsos}Proportion des modalités des
variables sociodémographiques des données de participation électorale.}

\end{figure}
\end{frame}

\begin{frame}{Analyse exploratoire}
\protect\hypertarget{analyse-exploratoire-1}{}
\includegraphics{MATH60602-diapos7_files/figure-beamer/figure-age-1.pdf}
\end{frame}

\begin{frame}{Analyse exploratoire (\texttt{age})}
\protect\hypertarget{analyse-exploratoire-age}{}
\begin{figure}

{\centering \includegraphics[width=0.7\textwidth,height=\textheight]{MATH60602-diapos7_files/figure-beamer/fig-vote-age-1.pdf}

}

\caption{\label{fig-vote-age}Fréquence de vote selon l'âge.}

\end{figure}

Notez le comportement des jeunes voteurs (bimodal). Ces personnes n'ont
souvent eu qu'une seule occasion de voter\ldots{}
\end{frame}

\begin{frame}{Régression pour données multinomiale}
\protect\hypertarget{ruxe9gression-pour-donnuxe9es-multinomiale}{}
On considère une variable réponse catégorielle avec \(K \ge 2\)
modalités.

\textbf{Objectif}: modéliser la probabilité de chaque catégorie de la
variable réponse.

Soit la probabilité d'appartenir à la modalité \(k\),
\[p_{ik} = \Pr(Y_i=k \mid \mathrm{X}_i), \qquad (k=1, \ldots, K).\]

La somme des probabilités, \(p_{i0} + \cdots + p_{iK}\), vaut 1.
\end{frame}

\begin{frame}{Modèle multinomial logistique}
\protect\hypertarget{moduxe8le-multinomial-logistique}{}
Comme avec la régression logistique, on fixe une catégorie de référence
(disons \(1\)) et on modélise le log de la cote de chacune des autres
catégories par rapport à cette référence, \begin{align*}
 \ln\left(\frac{p_{ij}}{p_{i1}}\right) = \eta_{ij} = \beta_{0j} + \cdots + \beta_{pj} \mathrm{X}_{ip}, \quad (j=2, \ldots, K).
\end{align*}

\begin{itemize}
\tightlist
\item
  Avec \(K\) modalités et \(p\) variables explicatives, on obtiendra
  \((K-1)\times (p+1)\) paramètres à estimer, en incluant l'ordonnée à
  l'origine.
\end{itemize}

L'interprétation des paramètres se fait comme en régression logistique
sauf qu'il faut y aller équation par équation.
\end{frame}

\begin{frame}{Modèle logistique multinomial et probabilités}
\protect\hypertarget{moduxe8le-logistique-multinomial-et-probabilituxe9s}{}
On peut aussi exprimer le modèle en termes des probabilités,
\begin{align*}
 p_{ik} &= \Pr(Y_i=k \mid \mathbf{X}_i) \\&= \frac{\exp(\eta_{ik})}{1+ \exp(\eta_{i2}) + \cdots + \exp(\eta_{iK})}, \qquad k =1, \ldots, K.
\end{align*} où \(\eta_{ij}\) est le prédicteur linéaire de l'individu
\(i\) pour le log de la cote de \(Y_i=j\) versus la référence \(Y_i=1\).
On fixe \(\eta_{i1}=0\).
\end{frame}

\begin{frame}[fragile]{Ajustement du modèle}
\protect\hypertarget{ajustement-du-moduxe8le}{}
La fonction \texttt{multinom} du paquet \texttt{nnet} ajuste le modèle
multinomial logistique.

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{data}\NormalTok{(vote, }\AttributeTok{package =} \StringTok{"hecmulti"}\NormalTok{)}
\FunctionTok{levels}\NormalTok{(vote}\SpecialCharTok{$}\NormalTok{catvote)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "rarement/jamais"   "occasionnellement" "toujours"         
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{\# Modèle multinomial}
\NormalTok{multi1 }\OtherTok{\textless{}{-}}\NormalTok{ nnet}\SpecialCharTok{::}\FunctionTok{multinom}\NormalTok{(}
\NormalTok{  catvote }\SpecialCharTok{\textasciitilde{}}\NormalTok{ age }\SpecialCharTok{+}\NormalTok{ sexe }\SpecialCharTok{+}\NormalTok{ race }\SpecialCharTok{+}\NormalTok{ revenu }\SpecialCharTok{+} 
\NormalTok{    educ }\SpecialCharTok{+}\NormalTok{ affiliation, }
  \AttributeTok{data =}\NormalTok{ vote,       }\CommentTok{\# base de données}
  \AttributeTok{subset =}\NormalTok{ age }\SpecialCharTok{\textgreater{}} \DecValTok{30}\NormalTok{, }\CommentTok{\# sous{-}ensemble des données}
  \AttributeTok{weights =}\NormalTok{ poids,   }\CommentTok{\# poids de sondage}
  \AttributeTok{trace =} \ConstantTok{FALSE}\NormalTok{)     }\CommentTok{\# infos sur convergence}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Méthodes \textbf{R} pour l'analyse}
\protect\hypertarget{muxe9thodes-r-pour-lanalyse}{}
\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{\# Tableau résumé de l\textquotesingle{}ajustement}
\FunctionTok{summary}\NormalTok{(multi1)}
\CommentTok{\# Estimations des coefficients}
\FunctionTok{coef}\NormalTok{(multi1)}
\CommentTok{\# Intervalles de confiance (Wald)}
\FunctionTok{confint}\NormalTok{(multi1)}
\CommentTok{\# Critères d\textquotesingle{}information}
\FunctionTok{AIC}\NormalTok{(multi1)}
\FunctionTok{BIC}\NormalTok{(multi1)}
\CommentTok{\# Prédiction: probabilité de chaque modalité}
\FunctionTok{predict}\NormalTok{(multi1, }\AttributeTok{type =} \StringTok{"probs"}\NormalTok{)}
\CommentTok{\# Prédiction: classe la plus susceptible}
\FunctionTok{predict}\NormalTok{(multi1, }\AttributeTok{type =} \StringTok{"class"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Comparaison de modèles emboîtés}
\protect\hypertarget{comparaison-de-moduxe8les-embouxeetuxe9s}{}
Le modèle avec uniquement l'ordonnée à l'origine possède \(K-1\)
paramètres. Il retourne comme probabilité prédite la proportion
empirique de chaque catégorie.

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{multi\_cst }\OtherTok{\textless{}{-}}\NormalTok{ nnet}\SpecialCharTok{::}\FunctionTok{multinom}\NormalTok{(}
\NormalTok{  catvote }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{,}
  \AttributeTok{weights =}\NormalTok{ poids,}
  \AttributeTok{subset =}\NormalTok{ age }\SpecialCharTok{\textgreater{}} \DecValTok{30}\NormalTok{,}
  \AttributeTok{data =}\NormalTok{ vote,}
  \AttributeTok{trace =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{head}\NormalTok{(}\FunctionTok{predict}\NormalTok{(multi\_cst, }\AttributeTok{type =} \StringTok{"probs"}\NormalTok{), }\AttributeTok{n =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  rarement/jamais occasionnellement  toujours
1       0.2282527         0.4910229 0.2807244
2       0.2282527         0.4910229 0.2807244
3       0.2282527         0.4910229 0.2807244
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Tests de rapport de vraisemblance}
\protect\hypertarget{tests-de-rapport-de-vraisemblance}{}
On peut comparer des modèles emboîtés avec la fonction \texttt{anova}:
ici, on compare le modèle complet au même modèle, moins la variable
\texttt{sexe}.

\begin{longtable}[]{@{}rrrrr@{}}
\toprule\noalign{}
ddl resid & deviance & ddl & stat & valeur-p \\
\midrule\noalign{}
\endhead
9670 & 8514.54 & & & \\
9668 & 8504.74 & 2 & 9.8 & 0.01 \\
\bottomrule\noalign{}
\end{longtable}

La différence est significative à niveau 5\%, l'effet de \texttt{sexe}
est non null.
\end{frame}

\begin{frame}{Prédictions}
\protect\hypertarget{pruxe9dictions}{}
Pour un profil \(\mathbf{X}_i\) donné, on peut

\begin{itemize}
\tightlist
\item
  calculer chacun des \(K-1\) prédicteurs linéaires
  \(\widehat{\eta}_{i2}, \ldots, \widehat{\eta}_{iK}\).
\item
  écrire \(p_{ik} = p_{i1}\exp(\widehat{\eta}_{ik})\) (formule de la
  cote)
\item
  substituer cette mesure dans l'équation \(p_{i1} + \cdots + p_{iK}=1\)
\item
  isoler la prédiction numérique pour \(p_{i1}\).
\item
  en déduire les probabilités de succès de chaque modalité de \(Y\).
\end{itemize}

\textbf{Exemple au tableau}
\end{frame}

\begin{frame}{Classification}
\protect\hypertarget{classification}{}
La prédiction du modèle est une probabilité pour chacune des \(K\)
modalités.

On peut toujours classifier les événements

\begin{itemize}
\tightlist
\item
  avec \(K-1\) points de coupure\ldots{}
\item
  ou assigner à la modalité la plus probable
\end{itemize}

Avec les prédictions, on peut comparer les observations et les
prédictions à l'aide d'une matrice de confusion \(K \times K\).

\begin{itemize}
\tightlist
\item
  Le taux de bonne classification est toujours valide
\item
  Il existe des extensions multidimensionnelles de l'aire sous la courbe
\end{itemize}
\end{frame}

\begin{frame}{Matrice de confusion}
\protect\hypertarget{matrice-de-confusion}{}
\hypertarget{tbl-confusmat}{}
\begin{longtable}[]{@{}lrrr@{}}
\caption{\label{tbl-confusmat}Prédictions (lignes) versus observations
(colonnes) pour le résultat du sondage pour les personnes âgées de plus
de 30 ans.}\tabularnewline
\toprule\noalign{}
& rare & occas. & toujours \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
& rare & occas. & toujours \\
\midrule\noalign{}
\endhead
rare & 264 & 159 & 19 \\
occas. & 640 & 1820 & 843 \\
toujours & 76 & 421 & 605 \\
\bottomrule\noalign{}
\end{longtable}

Le taux de bonne classification est 2689/4847=0.55.
\end{frame}

\begin{frame}{Commentaires}
\protect\hypertarget{commentaires}{}
\begin{itemize}
\tightlist
\item
  Contrairement à la régression logistique, le nombre de paramètres
  augmente rapidement avec le nombre de variables explicatives, \(p\).
\item
  Il y a moins d'information pour estimer les paramètres qu'une
  régression linéaire: prévoir de plus grandes tailles d'échantillon.
\item
  Attention aux modalités à faible fréquence et à la répartition des
  variables explicatives au sein des différentes modalités.
\end{itemize}
\end{frame}

\begin{frame}{Données ordinales}
\protect\hypertarget{donnuxe9es-ordinales}{}
Outre la régression multinomiale logistique, on peut également
considérer la \emph{régression logistique cumulative à cotes
proportionnelles}.

\begin{itemize}
\tightlist
\item
  modèle plus parcimonieux que le modèle multinomial logistique,
\item
  mais au prix de postulats supplémentaires\ldots{}
\end{itemize}

Voir les notes de cours pour plus de détails.
\end{frame}

\begin{frame}{Récapitulatif}
\protect\hypertarget{ruxe9capitulatif-2}{}
\begin{itemize}
\tightlist
\item
  La régression multinomiale logistique pour une variable catégorielle à
  \(K\) niveaux est une extension directe de la régression logistique
  pour données binaires

  \begin{itemize}
  \tightlist
  \item
    la somme des probabilités vaut 1.
  \item
    il y a \(K-1\) équations de cote en termes des variables
    explicatives,
  \item
    donc le nombre de paramètres croît rapidement.
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Récapitulatif}
\protect\hypertarget{ruxe9capitulatif-3}{}
On met beaucoup l'accent sur l'interprétation des coefficients à
l'échelle de la cote.

\begin{itemize}
\tightlist
\item
  rapports de cote = modèle multiplicatif: la cote de catégorie \(k\) vs
  référence est multipliée par \(\exp(\beta_{jk})\) pour chaque
  augmentation de \(\mathrm{X}_j\) d'une unité.
\item
  les coefficients manquants (cote de \(Y=k\) vs \(Y=l\)) peut être
  déduits par des manipulations algébriques.
\end{itemize}
\end{frame}

\begin{frame}{Récapitulatif}
\protect\hypertarget{ruxe9capitulatif-4}{}
Les outils usuels d'inférence pour les modèles estimés par maximum de
vraisemblance sont applicables.

\begin{itemize}
\tightlist
\item
  intervalles de confiance (Wald ou vraisemblance profilée)
\item
  tests de rapport de vraisemblance
\item
  critères d'information
\end{itemize}
\end{frame}

\begin{frame}{Récapitulatif}
\protect\hypertarget{ruxe9capitulatif-5}{}
Côté classification, on va règle générale assigner à la classe la plus
probable.

\begin{itemize}
\tightlist
\item
  il existe des équivalents multidimensionnels directs à ce qu'on a
  couvert (matrice de confusion, taux de bonne classification, gain,
  etc.)
\item
  certains concepts (sensibilité, spécificité, fonction d'efficacité du
  récepteur) ne sont en revanche pas applicables ou n'ont pas
  d'équivalent.
\end{itemize}
\end{frame}



\end{document}
