---
title: "Régression logistique: prédictions et données multinomiales"
subtitle: "Analyse multidimensionnelle appliquée"
date: "automne 2022"
author: "Léo Belzile"
institute: "HEC Montréal"
format: beamer
navigation: empty
colortheme: Flip
innertheme: Flip
outertheme: Flip
themeoptions: "bullet=circle, topline=true, shadow=false"
beamerarticle: false
pdf-engine: lualatex
cache: true
code-line-numbers: true
fig-align: 'center'
mainfont: "D-DIN"
mathfont: 'Latin Modern Math'
sansfont: 'Latin Modern Sans'
keep-tex: true
include-in-header: 
      text: |
        \usepackage{tabu}
        \usepackage{mathtools}
        \usepackage{mathrsfs}
---



# Sélection de variables en régression logistique

- On applique les mêmes principes que précédemment.
- Notre mesure d'ajustement (gain, taux de bonne classification, log-vraisemblance) peut différer selon l'objectif.
- Les modèles de régression logistique sont plus coûteux à estimer.
- Pour la classification, le point de coupure est à déterminer.

# Fonctions **R** pour la sélection de modèles

- `glmbb::glmbb` permet une recherche exhaustive de tous les sous-modèles à au plus une certaine distance (`cutoff`) du modèle avec le plus petit critère d'information (`criterion`).
- `step` permet de faire une recherche séquentielle avec un critère d'information.
- `glmulti::glmulti` permet une recherche exhaustive (`method = "h"`) ou par le biais d'un algorithme génétique (`method = "g"`).
- `glmnet::glmnet` permet d'ajuster le modèle avec pénalité LASSO.

Voir le [code en ligne](https://lbelzile.github.io/math60602/05-reglogistique.html#s%C3%A9lection-de-variables-en-r%C3%A9gression-logistique).

# Objectif du ciblage marketing

Déterminer si le revenu prévu justifie l'envoi du catalogue

$$\mathsf{E}(\textsf{ymontant}_i) = \mathsf{E}(\textsf{ymontant}_i \mid \textsf{yachat}_i = 1)\Pr(\textsf{yachat}_i = 1).$$

On peut combiner un modèle de régression logistique avec la régression linéaire (ajustés simultanément avec un modèle Heckit).

Ou simplement ignorer le montant d'achat et envoyer un catalogue si la probabilité d'achat excède notre point de coupure optimal.

# Stratégie de référence

- Parmi les 100K clients, 23 179 auraient acheté si on leur avait envoyé le catalogue
- Ces clients auraient généré des revenus de 1 601 212\$.
- Si on enlève le coût des envois (100 000 $\times$ 10\$), la stratégie de référence permet un revenu net de 601 212\$.


# Stratégie d'ajustement


En résumé, la procédure numérique à réaliser est la suivante:

- Choisir les variables à essayer (termes quadratiques, interactions, etc.)
- Choisir l'algorithme ou la méthode de sélection du modèle.
- Construire un catalogue de modèles: pour chacun, calculer les prédictions par validation croisée.
- Calculer le point de coupure optimal pour chaque modèle selon la fonction de gain moyen.
- Sélectionner le modèle qui **maximise le gain**.

# Prédiction et envoi

- Prédire les 100 000 observations de l'échantillon test.
- Envoyer un catalogue si la probabilité d'achat excède le point de coupure.
- Calculer le revenu résultant:
    - zéro si on n'envoie pas de catalogue
    - $-10$ si la personne n'achète pas
    - $-10$ plus l'achat si la personne achète.

**En pratique**, on ne pourrait pas *a priori* connaître le revenu résultant de cette stratégie.

# Conclusion


Si on avait fait une bête recherche séquentielle et qu'on avait pris le modèle avec le plus petit BIC (8 variables explicatives), on aurait dégagé des revenus de 978 226\$.

C’est une énorme amélioration, de plus de 56%, par rapport à la stratégie de référence.


# Récapitulatif

- Les principes de sélection de variable couverts précédemment s'appliquent toujours (recherche exhaustive, séquentielle et LASSO).
- On peut aussi calculer les critères d'information puisque le modèle est ajusté par maximum de vraisemblance.
- Attention au surajustement! Suspect si les probabilités estimées sont près de 0/1 (vérifier la calibration).
- Deux étapes: sélectionner le modèle (variables) et le point de coupure.
- D'autres modèles que la régression logistique (arbres de classification, etc.) sont envisageables pour la classification.

# Régression pour données multinomiale

On considère une variable réponse catégorielle avec $K \ge 2$ modalités.

**Objectif**: modéliser la probabilité de chaque catégorie de la variable réponse.

Soit la probabilité d'appartenir à la modalité $k$, $$p_{ik} = \Pr(Y_i=k \mid \mathrm{X}_i), \qquad (k=1, \ldots, K).$$ 

La somme des probabilités, $p_{i0} + \cdots + p_{iK}$, vaut 1.

# Modèle multinomial logistique 

Comme avec la régression logistique, on fixe une catégorie de référence (disons `1`) et on modélise le log de la cote de chacune des autres catégories par rapport à cette référence,
\begin{align*}
 \ln\left(\frac{p_{ij}}{p_{i1}}\right) = \eta_{ij} = \beta_{0j} + \beta_{1j} \mathrm{X}_{i1} + \cdots + \beta_{pj} \mathrm{X}_{ip}, \quad (j=2, \ldots, K).
\end{align*}

- Avec $K$ modalités et $p$ variables explicatives, on obtiendra $(K-1)\times (p+1)$ paramètres à estimer, en incluant l'ordonnée à l'origine.

L'interprétation des paramètres se fait comme en régression logistique sauf qu'il faut y aller équation par équation.

# Modèle logistique multinomial et probabilités 

On peut aussi exprimer le modèle en termes des probabilités,
\begin{align*}
 p_{i1} &= \Pr(Y_i=1 \mid \mathbf{X}_i) = \frac{1}{1+ \exp(\eta_{i2}) + \cdots + \exp(\eta_{iK})}\\
 p_{ik} &= \Pr(Y_i=k \mid \mathbf{X}_i) = \frac{\exp(\eta_{ik})}{1+ \exp(\eta_{i2}) + \cdots + \exp(\eta_{iK})}, \qquad k =2, \ldots, K.
\end{align*}
où $\eta_{ij}$ est le prédicteur linéaire de l'individu $i$ pour le log de la cote de $Y_i=j$ versus la référence $Y_i=1$.

# Taux de participation lors des élections américaines

Les [données](https://github.com/fivethirtyeight/data/tree/master/non-voters) de cet exemple sont tirées d'un sondage Ipsos réalisé pour le site de nouvelles *FiveThirtyEight*. 

La base de données `vote` contient 5837 observations avec les pondérations associées.

Nous allons modéliser l'intention de vote, `catvote` à l'aide d'une régression logistique multinomiale.

# Analyse exploratoire

```{r}
#| label: fig-multinom_means-Ipsos
#| echo: false
#| eval: true
#| out-width: '80%'
#| fig-width: 8
#| fig-height: 6
#| cache: true
#| fig-cap: "Proportion des modalités des variables sociodémographiques des données de participation électorale."
library(ggplot2)
library(dplyr)
library(patchwork)
data(vote, package = "hecmulti")
g1 <- vote |> 
  dplyr::count(revenu, catvote, wt = poids) |>
ggplot(aes(fill = catvote,
           x = n,
           y = revenu)) +
  ggplot2::geom_bar(position = "fill",
                    stat = "identity") +
  scale_x_continuous(name = NULL,
                     position = "top",
                     expand = c(0,0),
                     breaks = c(0, 0.25,0.5,0.75,1),
                     labels = c("0%","25","50","75","100")) +
  scale_y_discrete(expand = c(0,0)) +
  labs(subtitle = "revenu", 
       x = "", y = "", fill = "vote") +
  theme_classic()
g2 <- vote |> 
  dplyr::count(sexe, catvote, wt = poids) |>
ggplot(aes(fill = catvote,
           x = n,
           y = sexe)) +
  ggplot2::geom_bar(position = "fill",
                    stat = "identity") +
  scale_x_continuous(name = NULL,
                     position = "top",
                     expand = c(0,0),
                     breaks = c(0, 0.25,0.5,0.75,1),
                     labels = c("0%","25","50","75","100")) +
  scale_y_discrete(expand = c(0,0)) +
  labs(subtitle = "sexe", 
       x = "", y = "", fill = "vote") +
  theme_classic()
g3 <- vote |> 
  dplyr::count(race, catvote, wt = poids) |>
ggplot(aes(fill = catvote,
           x = n,
           y = race)) +
  ggplot2::geom_bar(position = "fill",
                    stat = "identity") +
  scale_x_continuous(name = NULL,
                     position = "top",
                     expand = c(0,0),
                     breaks = c(0, 0.25,0.5,0.75,1),
                     labels = c("0%","25","50","75","100")) +
  scale_y_discrete(expand = c(0,0)) +
  labs(subtitle = "race", 
       x = "", y = "", fill = "vote")+
  theme_classic()
g4 <- vote |> 
  dplyr::count(educ, catvote, wt = poids) |>
ggplot(aes(fill = catvote,
           x = n,
           y = educ)) +
  ggplot2::geom_bar(position = "fill",
                    stat = "identity") +
  scale_x_continuous(name = NULL,
                     position = "top",
                     expand = c(0,0),
                     breaks = c(0, 0.25,0.5,0.75,1),
                     labels = c("0%","25","50","75","100")) +
  scale_y_discrete(expand = c(0,0)) +
  labs(subtitle = "niveau d'éducation", 
       x = "", y = "", fill = "vote")+
  theme_classic()
g5 <- vote |> 
  dplyr::count(affiliation, catvote, wt = poids) |>
ggplot(aes(fill = catvote,
           x = n,
           y = affiliation)) +
  ggplot2::geom_bar(position = "fill",
                    stat = "identity") +
  scale_x_continuous(name = NULL,
                     position = "top", 
                     expand = c(0,0),
                     breaks = c(0, 0.25,0.5,0.75,1),
                     labels = c("0%","25","50","75","100")) +
  scale_y_discrete(expand = c(0,0)) +
  labs(subtitle = "affiliation politique", 
       x = "", y = "", fill = "vote")+
  theme_classic()
g6 <- vote |> 
  mutate(agecat = with(vote, cut(age, c(20,40,60,100)))) |>
  dplyr::count(agecat, catvote, wt = poids) |>
ggplot(aes(fill = catvote,
           x = n,
           y = agecat)) +
  ggplot2::geom_bar(position = "fill",
                    stat = "identity") +
  scale_x_continuous(name = NULL,
                     position = "top", 
                     breaks = c(0, 0.25,0.5,0.75,1),
                     labels = c("0%","25","50","75","100"),
                     expand = c(0,0)) +
  scale_y_discrete(expand = c(0,0)) +
  labs(subtitle = "âge", 
       x = "", y = "", fill = "vote") +
  theme_classic()
(g1 + g2) / (g3 +g4) / (g5 + g6) + plot_layout(guides = "collect") & theme(legend.position = "bottom")
```


# Analyse exploratoire  (`age`)

```{r}
#| label: fig-vote-age
#| eval: true
#| echo: false
#| fig-width: 6
#| fig-height: 4
#| out-width: '70%'
#| fig-cap: "Fréquence de vote selon l'âge."
ggplot(data = vote, 
       aes(x = age, fill = catvote)) +
  geom_density(alpha = 0.2) + 
  labs(fill = "vote", 
       x = "âge (années)", 
       y = "densité") + 
  theme(legend.position = "bottom") +
  theme_minimal()
```
Notez le comportement des jeunes voteurs (bimodal). Ces personnes n'ont souvent eu qu'une seule occasion de voter...


# Ajustement du modèle

La fonction `multinom` du paquet `nnet` ajuste le modèle multinomial logistique.

```{r}
#| label: mullogit
#| eval: true
#| echo: true
data(vote, package = "hecmulti")
levels(vote$catvote)
# Modèle multinomial
multi1 <- nnet::multinom(
  catvote ~ age + sexe + race + revenu + 
    educ + affiliation, 
  data = vote,       # base de données
  subset = age > 30, # sous-ensemble des données
  weights = poids,   # poids de sondage
  trace = FALSE)     # infos sur convergence
```

# Méthodes **R** pour l'analyse

```{r}
#| eval: false
#| echo: true
# Tableau résumé de l'ajustement
summary(multi1)
# Estimations des coefficients
coef(multi1)
# Intervalles de confiance (Wald)
confint(multi1)
# Critères d'information
AIC(multi1)
BIC(multi1)
# Prédiction: probabilité de chaque modalité
predict(multi1, type = "probs")
# Prédiction: classe la plus susceptible
predict(multi1, type = "class")
```

# Comparaison de modèles emboîtés

Le modèle avec uniquement l'ordonnée à l'origine possède $K-1$ paramètres.
Il retourne comme probabilité prédite la proportion empirique de chaque catégorie.

```{r}
#| eval: false
#| echo: true
multi0 <- nnet::multinom(catvote ~ 1,
                         weights = poids,
			 subset = age > 30,
                         data = vote,
                         trace = FALSE)
# Test de rapport de vraisemblance
anova(multi0, multi1)
```

```{r}
#| eval: true
#| echo: false
multi0 <- nnet::multinom(catvote ~ 1,
			 subset = age > 30,
                         weights = poids,
                         data = vote,
                         trace = FALSE)
# Test de rapport de vraisemblance
options(knitr.kable.NA = '')
knitr::kable(anova(multi0, multi1)[,-1], digits = 2)
```

# Prédictions

Pour un profil $\mathbf{X}_i$ donné, on peut 

- calculer chacun des $K-1$ prédicteurs linéaires $\widehat{\eta}_{i2}, \ldots, \widehat{\eta}_{iK}$.
- écrire $p_{ik} = p_{i1}\exp(\widehat{\eta}_{ik})$ (formule de la cote)
- substituer cette mesure dans l'équation $p_{i1} + \cdots + p_{iK}=1$
- isoler la prédiction numérique pour $p_{i1}$.
- en déduire les probabilités de succès de chaque modalité de $Y$.

**Exemple au tableau**


# Classification

La prédiction du modèle est une probabilité pour chacune des $K$ modalités.


On peut toujours classifier les événements 

- avec $K-1$ points de coupure...
- ou assigner à la modalité la plus probable

Avec les prédictions, on peut comparer les observations et les prédictions à l'aide d'une matrice de confusion $K \times K$.

- Le taux de bonne classification est toujours valide
- Il existe des extensions multidimensionnelles de l'aire sous la courbe

# Commentaires

- Contrairement à la régression logistique, le nombre de paramètres augmente rapidement avec le nombre de variables explicatives, $p$.
- Il y a moins d'information pour estimer les paramètres qu'une régression linéaire: prévoir de plus grandes tailles d'échantillon.
- Attention aux modalités à faible fréquence et à la répartition des variables explicatives au sein des différentes modalités.

# Données ordinales

Outre la régression multinomiale logistique, on peut également considérer la *régression logistique cumulative à cotes proportionnelles*.


- modèle plus parcimonieux que le modèle multinomial logistique,
- mais au prix de postulats supplémentaires...

En **R**, la variable réponse doit être de classe `ordered`, un facteur dont les niveaux sont ordonnés en ordre croissant.
```{r}
#| echo: true
#| eval: true
class(hecmulti::vote$catvote)
```

# Notation du modèle

Soit $p_1, \ldots, p_K$ les probabilités associées aux événements $Y=1, \ldots, Y=K$.
On définit les points de coupure pour les $K$ classes,
$$ -\infty = \zeta_0 < \zeta_1 < \cdots < \zeta_K = \infty.$$
Il y a $K-1$ paramètres $\zeta$ à déduire pour identifier les probabilités puisque $p_1 + \cdots + p_K=1$.

#  Formulation du modèle

Le modèle logistique à cote proportionnelle spécifie $K-1$ équations logistiques; pour $k=1, \ldots, K-1$,
\begin{align*}
\ln \left(\frac{\Pr(Y_i> k\mid \mathbf{X}_i)}{\Pr(Y_i \le k\mid \mathbf{X}_i)}\right) = -\zeta_k + \beta_1 \mathrm{X}_{i1} + \cdots + \beta_p \mathrm{X}_{ip}.
\end{align*}

- Les paramètres associés aux variables explicatives, $\beta_1, \ldots, \beta_p$ sont les **mêmes** pour chacune des log-cotes
- mais il y a une ordonnée à l'origine différente par rapport de cote, $-\zeta_k$. 


# Interprétation des paramètres

On considère la cote de $\Pr(Y_i> k\mid \mathbf{X}_i)$ versus $\Pr(Y_i \le k\mid \mathbf{X}_i)$, qui mesure à quel point il est plus probable que $Y_i$ prenne une valeur supérieure à $k$ par rapport à une valeur inférieure ou égale à $k$, avec

Pour chaque augmentation d'une unité de $\mathrm{X}_j$, cette cote est multipliée par $\exp(\beta_j)$, peu importe la valeur de $Y$ (**cote proportionnelle**). 

# Interprétation des coefficients

```{r}
#| label: tbl-ordered-logistic
#| tbl-cap: "Tableau des estimations des coefficients du modèle pour réponses ordinales pour la régression logistique à cotes proportionnelles avec sexe."
#| echo: false
#| eval: true
#| message: false
#| warning: false
multi2a <- MASS::polr(catvote ~ sexe, 
                      data = vote,
                      subset = age > 30,
                      weights = poids,
                      method = "logistic", 
                      Hess = TRUE)
# multi2b <- nnet::multinom(
#   catvote ~ affiliation, 
#   data = vote,
#   subset = age > 30,
#   weights = poids,
#   Hess = TRUE,
#   trace = FALSE)
rapp <- summary(multi2a)
coefs <- rapp$coefficients
options(knitr.kable.NA = '')
tabcoef <- tibble::as_tibble(coefs[,1:2])
tabcoef <- cbind("effet" = c("sexe [homme]","cst [rarement/jamais|occasionnellement]","cst [occasionnellement|toujours]"), tabcoef)
kableExtra::kbl(tabcoef,
	        longtable = FALSE, 
	        booktabs = TRUE,
          col.names = c("effet","coefficient","erreur-type"),
          digits = 3,
	        format = "latex")
pval_lrt_multi2a_drop1 <- sprintf(round(drop1(multi2a, test = "Chisq")[2,4],3), fmt = "%.3f")
```

Les hommes de plus de 30 ans sont moins susceptibles de voter fréquemment que les femmes. 

La cote catégorie plus fréquente de vote (vs moins fréquente) pour les hommes est $\exp(`r sprintf(round(as.numeric(coef(multi2a)),3), fmt = "%.3f")`)=`r sprintf(round(exp(as.numeric(coef(multi2a))),3), fmt = "%.3f")`$ fois celle des femmes, soit une diminution de $`r round(100*(1-exp(as.numeric(coef(multi2a)))), 1)`\%$ de la cote.

# Ajustement dans **R**

Pour simplifier, on utilise uniquement `sexe` comme variable explicative.

```{r}
#| label: ordinal-logistique
#| eval: false
#| echo: true
#| warning: false
#| error: false
# with(vote, is.ordered(catvote))
multi2a <- MASS::polr(
  catvote ~ sexe, 
  data = vote, 
  subset = age > 30,
  weights = poids,
  method = "logistic", 
  Hess = TRUE)
summary(multi2a)
```

```{r}
#| label: ordinal-logistique-eval
#| eval: true
#| echo: false
#| warning: false
#| error: false
# with(vote, is.ordered(catvote))
multi2a <- MASS::polr(
  catvote ~ sexe, 
  data = vote, 
  subset = age > 30,
  weights = poids,
  method = "logistic", 
  Hess = TRUE)
expit <- function(x){ exp(x)/(1+exp(x))}
```


# Méthodes pour `polr`


```{r}
#| echo: true
#| eval: false
# IC pour beta_x (vraisemblance profilée)
confint(multi2a)
# On peut obtenir les intervalles de Wald 
# avec confint.default (PAS RECOMMANDÉ)

# Critères d'information
AIC(multi2a); BIC(multi2a)
# Tableau des coefficients 
# Coefficients (variables explicatives)
coef(multi2a)
# Négatif de l'ordonnée à l'origine:
multi2a$zeta
```

# Coefficients pour l'ordonnée à l'origine


Si on écrit les équations pour la cote, on obtient
\begin{align*}
\frac{\Pr(Y = \texttt{rarement} \mid \texttt{sexe})}{\Pr(Y \geq \texttt{occasionnellement} \mid \texttt{sexe})} &= \exp(`r round(coef(multi2a)[1], 3)`\texttt{sexe} `r paste(ifelse(multi2a$zeta[1] < 0, "+","-"), round(abs(multi2a$zeta[1]), 3))`) \\ 
\frac{\Pr(Y \leq \texttt{occasionnellement} \mid \texttt{sexe})}{\Pr(Y = \texttt{toujours} \mid \texttt{sexe})} &= \exp(`r round(coef(multi2a)[1], 3)`\texttt{sexe} `r paste(ifelse(multi2a$zeta[2] < 0, "+","-"), round(abs(multi2a$zeta[2]), 3))`).
\end{align*}

# Probabilités prédites

En terme de probabilité cumulée d'excéder $k$,
\begin{align*}
\Pr(Y_i > k \mid \mathbf{X}_i) &= \textrm{expit}(-\eta_k + \beta_1 \mathrm{X}_{i1} + \cdots + \beta_p \mathrm{X}_{ip}), \qquad k=1, \ldots, K-1.
\end{align*}
En utilisant ces expressions, on peut obtenir la probabilité de chaque catégorie,
\begin{align*}
&\Pr(Y_i = k \mid \mathbf{X}_{i}) =\Pr(Y_i > k \mid \mathbf{X}_{i}) - \Pr(Y_i > k-1 \mid \mathbf{X}_{i}).
\end{align*}

# Prédictions

- Soit $p_1 = \Pr(Y = \texttt{rarement/jamais} \mid \texttt{femme})$, etc. 
- On a $\mathrm{expit}(\zeta_k)$ ($k=0, \ldots, K$) qui donne $0$, $`r round(expit(multi2a$zeta)[1], 3)`$, $`r round(expit(multi2a$zeta)[2], 3)`$ et $1$.
- Les différences donnent $\widehat{p}_1 = `r round(expit(multi2a$zeta)[1], 3)`$, $\widehat{p}_2 = `r round(expit(multi2a$zeta)[2]-expit(multi2a$zeta)[1], 3)`$ et $\widehat{p}_3 = `r round(1-expit(multi2a$zeta)[2], 3)`$. 
- Un rapide calcul numérique montre que c'est bien ce que retourne les prédictions.

```{r}
#| eval: false
#| echo: true
predict(multi2a, 
        newdata = data.frame(sexe = factor("femme")), 
        type = "probs")
```


# Postulat de rapport de cote proportionnel

Une des hypothèses de ce modèle est que les effets des variables explicatives sont les mêmes pour chaque équation. 

- $\mathscr{H}_0$ : l'effet de chaque variable est le même pour les $K$ logit du modèle .

Une très petite valeur-$p$ (rejet de $\mathscr{H}_0$) pour ce test serait une indication que le modèle multinomial logistique serait préférable. 

# Test de rapport de vraisemblance 

Ce test compare les deux modèles emboîtés, avec 

- hypothèse nulle $\mathscr{H}_0$: modèle cumulatif à cotes proportionnelles, avec $p+K-1$ paramètres
- hypothèse alternative $\mathscr{H}_a$: modèle multinomial, avec $(K-1)\times(p+1)$ paramètres


```{r}
#| eval: true
#| echo: true
multi2b <- nnet::multinom(catvote ~ sexe, 
  data = vote,  subset = age > 30, 
  weights = poids, trace = FALSE)
# Valeur-p du test de rapport de vraisemblance
pchisq(q = deviance(multi2a) - deviance(multi2b),
       df = length(coef(multi2a)), 
       lower.tail = FALSE)
```

Le modèle sous $\mathscr{H}_0$ semble être une simplification adéquate.

# Test du rapport de vraisemblance


```{r}
#| eval: true
#| echo: false
multi3a <- MASS::polr(
  catvote ~ age, 
  data = vote, 
  subset = age > 30,
  weights = poids,
  method = "logistic", 
  Hess = TRUE)
multi3b <- nnet::multinom(catvote ~ age, 
  data = vote,  subset = age > 30, 
  weights = poids, trace = FALSE)
# Valeur-p du test de rapport de vraisemblance
pval <- pchisq(q = deviance(multi3a) - deviance(multi3b),
       df = length(coef(multi2a)), 
       lower.tail = FALSE)
```

Si on ajuste plutôt le modèle avec uniquement `age`, la valeur-$p$ est inférieure à $10^{-5}$: le modèle cumulatif à cote proportionnelles ne serait pas une simplification adéquate.

On peut également effectuer des tests pour déterminer la significativité

 - la significativité globale (ordonnée à l'origine vs modèle complet)
 - l'effet d'une variable explicative (modèle complet, moins une variable)

# Comparaison des prédictions 

\footnotesize 
Prédictions pour le modèle avec uniquement `age` comme variable explicative.

```{r}
#| label: fig-predmultinom
#| fig-cap: "Probabilités prédites pour chaque modalité selon l'âge."
#| fig-width: 8
#| fig-height: 6
#| out-width: '70%'
#| cache: true
#| eval: true
#| echo: false
#| warning: false
library(MASS)
multi3a <- MASS::polr(
  catvote ~ scale(age, scale = FALSE), 
  data = vote,
  subset = age > 30, 
  weights = poids,
  method = "logistic", 
  Hess = TRUE)

multi3b <- nnet::multinom(
  catvote ~ scale(age, scale = FALSE), 
  data = vote,
  subset = age > 30, 
  weights = poids,
  Hess = TRUE,
  trace = FALSE)
xpred <- seq(30, 95, by = 0.1) - mean(vote$age)
nobs <- length(xpred)
pred1 <- predict(multi3b, 
                 newdata = data.frame(age = xpred),
                 type = "prob")
pred2 <- predict(multi3a, 
                 newdata = data.frame(age = xpred),
                 type = "prob")
df <- data.frame(
  x = rep(xpred + mean(vote$age), length.out = 6*nobs),
  modele = factor(rep(c("multinomial", "ordinal"), 
                       each = 3*nobs)),
  reponse = factor(c(rep(c("rarement/jamais",
                    "occasionnellement",
                    "toujours"), 
                  each = nobs),
                  rep(c("rarement/jamais",
                    "occasionnellement",
                    "toujours"), 
                  each = nobs))),
  pred = c(pred1, pred2))
                  
ggplot2::ggplot(
  data = df,
  mapping = ggplot2::aes(
    x = x,
    y = pred,
    color = reponse,
    linetype = modele)) + 
  ggplot2::geom_line() +
  ggplot2::labs(y = "probabilité prédite",
       linetype = "modèle",
       color = "vote",
       x = "âge (années)") +
  MetBrewer::scale_color_met_d("Hiroshige") + 
  ggplot2::theme_minimal() +
  ggplot2::theme(legend.position = "bottom") 
```

\normalsize

# Récapitulatif

- La régression multinomiale logistique pour une variable catégorielle à $K$ niveaux est une extension directe de la régression logistique pour données binaires
   - la somme des probabilités vaut 1.
   - il y a $K-1$ équations de cote en termes des variables explicatives,
   - donc le nombre de paramètres croît rapidement.
   
# Récapitulatif

On met beaucoup l'accent sur l'interprétation des coefficients à l'échelle de la cote.

   - rapports de cote = modèle multiplicatif: la cote de catégorie $k$ vs référence est multipliée par $\exp(\beta_{jk})$ pour chaque augmentation de $\mathrm{X}_j$ d'une unité.
   - les coefficients manquants (cote de $Y=k$ vs $Y=l$) peut être déduits par des manipulations algébriques.
    
# Récapitulatif

Les outils usuels d'inférence pour les modèles estimés par maximum de vraisemblance sont applicables.

 - intervalles de confiance (Wald ou vraisemblance profilée)
 - tests de rapport de vraisemblance
 - critères d'information

# Récapitulatif

Côté classification, on va règle générale assigner à la classe la plus probable.

- il existe des équivalents multidimensionnels directs à ce qu'on a couvert (matrice de confusion, taux de bonne classification, gain, etc.) 
- certains concepts (sensibilité, spécificité, fonction d'efficacité du récepteur) ne sont en revanche pas applicables ou n'ont pas d'équivalent.

# Récapitulatif

Le modèle cumulatif à cote proportionnelle est une simplification du modèle multinomial pour des **données ordinales**.

- On suppose que l'effet des variables est le même pour la cote de la survie de chaque modalité.
- Moins de paramètres, mais postulat à vérifier (via test de rapport de vraisemblance).
